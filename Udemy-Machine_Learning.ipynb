{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing te data\n",
    "data=pd.read_csv('/home/kinga/python/Machine_Learning/Machine Learning A-Z New/Part1-DataPreprocessing/Section2,Part1-Data_Preprocessing/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary\n",
       "0   France  44.0  72000.0\n",
       "1    Spain  27.0  48000.0\n",
       "2  Germany  30.0  54000.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features\n",
    "X=data[['Country', 'Age', 'Salary']]\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     No\n",
       "1    Yes\n",
       "2     No\n",
       "3     No\n",
       "4    Yes\n",
       "Name: Purchased, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the prediction target\n",
    "y=data['Purchased']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinga/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "imputer=Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imputer=imputer.fit(X[['Age','Salary']]) # fitting imputer object to X\n",
    "X.iloc[:,1:3]=imputer.transform(X.iloc[:,1:3]) #replace NaN with mean values from columns Age and Salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>72000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>48000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>54000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>63777.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>58000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.777778</td>\n",
       "      <td>52000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>83000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>67000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country        Age        Salary\n",
       "0   France  44.000000  72000.000000\n",
       "1    Spain  27.000000  48000.000000\n",
       "2  Germany  30.000000  54000.000000\n",
       "3    Spain  38.000000  61000.000000\n",
       "4  Germany  40.000000  63777.777778\n",
       "5   France  35.000000  58000.000000\n",
       "6    Spain  38.777778  52000.000000\n",
       "7   France  48.000000  79000.000000\n",
       "8  Germany  50.000000  83000.000000\n",
       "9   France  37.000000  67000.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinga/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "labelencoder_X=LabelEncoder() # object of class LabelEncoder\n",
    "X.iloc[:,0]=labelencoder_X.fit_transform(X.iloc[:, 0]) #returns first column of X encoded- \n",
    "#it means that if I select first columns I will not have countries' names but numbers \n",
    "# there is a problem with this method, because ML equation will compare those values and this is not true that \n",
    "# if France has number 0, it is lower that Spain with number 2\n",
    "# To prevent from this, we are going to use OneHotEncoder\n",
    "onehotencoder=OneHotEncoder(categorical_features=[0]) #categorical_features=0 -nummber of columns with categorical val\n",
    "X=onehotencoder.fit_transform(X).toarray() # we don't have to put column number because we specified it above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "        7.20000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "        4.80000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
       "        5.40000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "        6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "        6.37777778e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "        5.80000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "        5.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "        7.90000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
       "        8.30000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "        6.70000000e+04]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enoding prediction target y\n",
    "labelencoder_y=LabelEncoder() # object of class LabelEncoder\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X_train) # fit the object to training set and then transform it\n",
    "X_test=sc_X.transform(X_test) #we don't need to to fit it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>-0.774597</td>\n",
       "      <td>0.263068</td>\n",
       "      <td>0.123815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-0.774597</td>\n",
       "      <td>-0.253501</td>\n",
       "      <td>0.461756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>-1.975398</td>\n",
       "      <td>-1.530933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>-1.111420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-0.774597</td>\n",
       "      <td>1.640585</td>\n",
       "      <td>1.720297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>1.290994</td>\n",
       "      <td>-0.081312</td>\n",
       "      <td>-0.167514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-0.774597</td>\n",
       "      <td>0.951826</td>\n",
       "      <td>0.986148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-0.774597</td>\n",
       "      <td>-0.597881</td>\n",
       "      <td>-0.482149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4\n",
       "0 -1.0  2.645751 -0.774597  0.263068  0.123815\n",
       "1  1.0 -0.377964 -0.774597 -0.253501  0.461756\n",
       "2 -1.0 -0.377964  1.290994 -1.975398 -1.530933\n",
       "3 -1.0 -0.377964  1.290994  0.052614 -1.111420\n",
       "4  1.0 -0.377964 -0.774597  1.640585  1.720297\n",
       "5 -1.0 -0.377964  1.290994 -0.081312 -0.167514\n",
       "6  1.0 -0.377964 -0.774597  0.951826  0.986148\n",
       "7  1.0 -0.377964 -0.774597 -0.597881 -0.482149"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('/home/kinga/python/Machine_Learning/Machine Learning A-Z New/Part2-Regression/Section4-Simple_Linear_Regression/Salary_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience   Salary\n",
       "0              1.1  39343.0\n",
       "1              1.3  46205.0\n",
       "2              1.5  37731.0\n",
       "3              2.0  43525.0\n",
       "4              2.2  39891.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "X=dataset.iloc[:,0]\n",
    "\n",
    "#target \n",
    "y=dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
    "X_train = X_train.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in linear regression we don't need to take care of data scaling. This model will do it for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting simple linear regression to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test set results\n",
    "X_test= X_test.values.reshape(-1,1)\n",
    "y_pred=regressor.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(17,5))\n",
    "plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "# visualising the training test results\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train, y_train, color='red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue')\n",
    "plt.title('Salary vs experience (Training set)')\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Salary')\n",
    "\n",
    "# visualising the test set results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test, y_test, color='red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue') # trend line is the same as above because I want to see\n",
    "#how far are predicted values from trend line\n",
    "plt.title('Salary vs experience (Test set)')\n",
    "plt.xlabel('Years of experience')\n",
    "plt.ylabel('Salary')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 exercise-predicting prices of apartments using Linear Regression\n",
    "- in this exercise I will predict apartment's prices depending od their surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Adres', 'Cena', 'Cena_lokalu', 'Cena_z/m2',\n",
       "       'Data_transakcji', 'Forma obrotu', 'Funkcja dominujca',\n",
       "       'Funkcja podstawowa', 'Identyfikator', 'Ilo_izb', 'Kondygnacja',\n",
       "       'Liczba i rodzaj pomieszcze przynalenych', 'Nr zmiany', 'Numer KW',\n",
       "       'Numer transakcji/wyceny', 'Obrb', 'Opis', 'Opis nieruchomoci',\n",
       "       'Podstawa prawna', 'Pole powierzchni pomieszcze przynalenych',\n",
       "       'powierzchnia_lokalu', 'Rodzaj nieruchomoci', 'Rodzaj obcienia',\n",
       "       'Rodzaj prawa objtego transakcj', 'Rodzaj zapisu', 'repertorium',\n",
       "       'Udzia w prawie bdcy przedmiotem transakcji',\n",
       "       'Uzbrojenie istniejce', 'Uzbrojenie moliwe do podczenia',\n",
       "       'Wsprzdne geometryczne rodka budynku', 'miasto', 'adres_miasto',\n",
       "       'ulica', 'numer_mieszkania', 'wspolrzedne', 'dlugosc', 'szerokosc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "prices=pd.read_excel('/home/kinga/python/baza_bez_outliers.xlsx')\n",
    "prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=prices.loc[prices['Obrb']=='JEYCE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the index number of column 'Cena_z/m2'\n",
    "prices.columns.tolist().index('Cena_z/m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the index number of column 'powierzchnia_lokalu'\n",
    "prices.columns.tolist().index('powierzchnia_lokalu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing a feature which is surface\n",
    "X=prices.iloc[:, 22]\n",
    "# choosing target\n",
    "y=prices.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    240.000000\n",
       "mean      56.432167\n",
       "std       27.394913\n",
       "min       20.390000\n",
       "25%       37.290000\n",
       "50%       48.960000\n",
       "75%       66.100000\n",
       "max      166.900000\n",
       "Name: powierzchnia_lokalu, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     240.000000\n",
       "mean     4888.876542\n",
       "std      1380.816178\n",
       "min      1716.680000\n",
       "25%      3984.357500\n",
       "50%      4849.975000\n",
       "75%      5898.700000\n",
       "max      8061.220000\n",
       "Name: Cena_z/m2, dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=0)\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "X_test = X_test.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting linear regression to the training test\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(17,5))\n",
    "plt.subplots_adjust(wspace=0.2) # space between plots\n",
    "\n",
    "# visualising the training test results\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train, y_train, color='red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue')\n",
    "plt.title('Price dependence on the surface (training set)')\n",
    "plt.xlabel('Surface')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# visualising the test set results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test, y_test, color='red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color='blue') # trend line is the same as above because I want to see\n",
    "#how far are predicted values from trend line\n",
    "plt.title('Price dependence on the surface (test set)')\n",
    "plt.xlabel('Surface')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above graphs show that there is a correlation between surface and price (the higher surface, the lower price), \n",
    "# but there are also other factors that infulence the price for egg. location, standard etc. That's why predictions \n",
    "# are not very accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "startups=pd.read_csv(\n",
    "'/home/kinga/python/Machine_Learning/Machine Learning A-Z New/Part2-Regression/Section5-MultipleLinearRegression/50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this exercise I will check the impact of R&D Spend, Administration Spend, Marketing Spend and State on the profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing features\n",
    "X=startups.iloc[:,0:4]\n",
    "# choosing predicting target\n",
    "y=startups.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical data (X)\n",
    "# encoding independent value (y)\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "Labelencoder_X=LabelEncoder()\n",
    "X.iloc[:,3]=Labelencoder_X.fit_transform(X.iloc[:, 3]) # column 'State'-change states' names to numbers\n",
    "onehotencoder=OneHotEncoder(categorical_features=[3]) # making Dummy Variables to column 'state'\n",
    "X=onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoiding the Dummy Variable Trap. Actually we don't have to do it as the library will do it for us\n",
    "X=X[:, 1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting Multiple Linear Regression to te training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train) # fitting the object to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "      <th>Predicted_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103282.38</td>\n",
       "      <td>104440.725826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144259.40</td>\n",
       "      <td>132253.815677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146121.95</td>\n",
       "      <td>132872.071743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77798.83</td>\n",
       "      <td>71707.787714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191050.39</td>\n",
       "      <td>178678.993499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Profit  Predicted_profit\n",
       "0  103282.38     104440.725826\n",
       "1  144259.40     132253.815677\n",
       "2  146121.95     132872.071743\n",
       "3   77798.83      71707.787714\n",
       "4  191050.39     178678.993499"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of real and predicted profits\n",
    "real_profits=y_test.reset_index(drop=True)\n",
    "predicted_profits=pd.Series(y_pred, name='Predicted_profit')\n",
    "comparison=pd.concat([real_profits,predicted_profits], axis=1)\n",
    "comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Building the optimal model using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "# appending a column with constant value\n",
    "X=np.append(arr=np.ones((50, 1)).astype(int), values=X, axis=1) # 50 rows, 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the optimal matrix of features (contains only features that are statistically siginificant)\n",
    "X_opt=X[:,[0,1,2,3,4,5]] # choosing indexes of features that are going to be considered\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000000e+00, 0.000000e+00, 1.000000e+00, 1.653492e+05,\n",
       "       1.368978e+05, 4.717841e+05])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:35</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Sun, 25 Aug 2019   Prob (F-statistic):           1.34e-27\n",
       "Time:                        18:57:35   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1063.\n",
       "Df Residuals:                      44   BIC:                             1074.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
       "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
       "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()\n",
    "#x1- dummy variable (State)\n",
    "#x2- dummy variable (State)\n",
    "#x3- R&D Spend\n",
    "#x4- Administration\n",
    "#x5- Marketing Spend\n",
    "# the statistic shows that the highest P-value has x2(0,990) so I have to remove it in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing feature with the highest P-value (x2)\n",
    "X_opt=X[:,[0,1,3,4,5]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:39</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Sun, 25 Aug 2019   Prob (F-statistic):           8.49e-29\n",
       "Time:                        18:57:39   Log-Likelihood:                -525.38\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
       "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()\n",
    "#x1- dummy variable (State)\n",
    "#x2- R&D Spend\n",
    "#x3- Administration\n",
    "#x4- Marketing Spend\n",
    "# the statistic shows that the highest P-value has x1(0,940) so I have to remove it in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing feature with the highest P-value\n",
    "X_opt=X[:,[0,3,4,5]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:42</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Sun, 25 Aug 2019   Prob (F-statistic):           4.53e-30\n",
       "Time:                        18:57:42   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()\n",
    "#x1- R&D Spend\n",
    "#x2- Administration\n",
    "#x3- Marketing Spend\n",
    "# the statistic shows that the highest P-value has x2(0,600) so I have to remove it in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt=X[:,[0,3,5]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:49</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Sun, 25 Aug 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        18:57:49   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()\n",
    "#x1- R&D Spend\n",
    "#x2- Marketing Spend\n",
    "# the statistic shows that the highest P-value has x2(0,06). \n",
    "# It is really close to the statistically significant value(P<0,05) so I can decide to leave it or remove\n",
    "# For the purpose of this exercise (backward elimination) I will remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Profit</td>      <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:53</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Profit   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Sun, 25 Aug 2019   Prob (F-statistic):           3.50e-32\n",
       "Time:                        18:57:53   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt=X[:,[0,3]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt1=X[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_opt, y, random_state=0)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train) # fitting the object to the training set\n",
    "\n",
    "y_pred_opt=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104560.72466151],\n",
       "       [134156.63684656],\n",
       "       [135217.63082962],\n",
       "       [ 71940.15211233],\n",
       "       [179267.6454832 ],\n",
       "       [109737.87468807],\n",
       "       [ 65389.01521965],\n",
       "       [100358.92792475],\n",
       "       [111350.97673001],\n",
       "       [169578.4243176 ],\n",
       "       [ 95535.39411668],\n",
       "       [ 87431.30370649],\n",
       "       [112491.63587783]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_opt is two dimensional array. I change it into one dimensional\n",
    "y_pred_opt=np.concatenate(y_pred_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104560.72466151, 134156.63684656, 135217.63082962,  71940.15211233,\n",
       "       179267.6454832 , 109737.87468807,  65389.01521965, 100358.92792475,\n",
       "       111350.97673001, 169578.4243176 ,  95535.39411668,  87431.30370649,\n",
       "       112491.63587783])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "      <th>Predicted profit without Backward Elimination</th>\n",
       "      <th>Predicted profit with Backward Elimination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103282.38</td>\n",
       "      <td>104440.725826</td>\n",
       "      <td>104560.724662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144259.40</td>\n",
       "      <td>132253.815677</td>\n",
       "      <td>134156.636847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146121.95</td>\n",
       "      <td>132872.071743</td>\n",
       "      <td>135217.630830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77798.83</td>\n",
       "      <td>71707.787714</td>\n",
       "      <td>71940.152112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191050.39</td>\n",
       "      <td>178678.993499</td>\n",
       "      <td>179267.645483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Profit  Predicted profit without Backward Elimination  \\\n",
       "0  103282.38                                  104440.725826   \n",
       "1  144259.40                                  132253.815677   \n",
       "2  146121.95                                  132872.071743   \n",
       "3   77798.83                                   71707.787714   \n",
       "4  191050.39                                  178678.993499   \n",
       "\n",
       "   Predicted profit with Backward Elimination  \n",
       "0                               104560.724662  \n",
       "1                               134156.636847  \n",
       "2                               135217.630830  \n",
       "3                                71940.152112  \n",
       "4                               179267.645483  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of real and predicted profits received with and without Backward Elimination\n",
    "real_profits=y_test.reset_index(drop=True)\n",
    "predicted_profits_without_BE=pd.Series(y_pred, name='Predicted profit without Backward Elimination')\n",
    "predicted_profits_with_BE=pd.Series(y_pred_opt, name='Predicted profit with Backward Elimination')\n",
    "comparison=pd.concat([real_profits,predicted_profits_without_BE,predicted_profits_with_BE], axis=1)\n",
    "comparison.head()\n",
    "# Comparison shows that in this case predicted profits are w bit more accurate when using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exercise-predicting prices of apartments using Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "real_estates=pd.read_excel('/home/kinga/python/Machine_Learning/transakcje_mieszkania.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Adres', 'Cena', 'Cena_lokalu', 'Cena_z/m2',\n",
       "       'Data_transakcji', 'Forma obrotu', 'Funkcja dominujca',\n",
       "       'Funkcja podstawowa', 'Identyfikator', 'Ilo_izb', 'Kondygnacja',\n",
       "       'Liczba i rodzaj pomieszcze przynalenych', 'Nr zmiany', 'Numer KW',\n",
       "       'Numer transakcji/wyceny', 'Obrb', 'Opis', 'Opis nieruchomoci',\n",
       "       'Podstawa prawna', 'Pole powierzchni pomieszcze przynalenych',\n",
       "       'powierzchnia_lokalu', 'Rodzaj nieruchomoci', 'Rodzaj obcienia',\n",
       "       'Rodzaj prawa objtego transakcj', 'Rodzaj zapisu', 'repertorium',\n",
       "       'Udzia w prawie bdcy przedmiotem transakcji',\n",
       "       'Uzbrojenie istniejce', 'Uzbrojenie moliwe do podczenia',\n",
       "       'Wsprzdne geometryczne rodka budynku', 'miasto', 'adres_miasto',\n",
       "       'ulica', 'numer_mieszkania', 'wspolrzedne', 'dlugosc', 'szerokosc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_estates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obrb</th>\n",
       "      <th>powierzchnia_lokalu</th>\n",
       "      <th>Kondygnacja</th>\n",
       "      <th>Cena_z/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>CHARTOWO</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5109.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>CHARTOWO</td>\n",
       "      <td>45.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5714.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>CHARTOWO</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4796.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>CHARTOWO</td>\n",
       "      <td>62.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4960.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>CHARTOWO</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3797.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Obrb  powierzchnia_lokalu  Kondygnacja  Cena_z/m2\n",
       "358  CHARTOWO                 64.0          NaN     5109.38\n",
       "482  CHARTOWO                 45.5          8.0     5714.29\n",
       "541  CHARTOWO                 64.0          1.0     4796.88\n",
       "721  CHARTOWO                 62.9          7.0     4960.25\n",
       "742  CHARTOWO                 79.0          6.0     3797.47"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_estates=real_estates[['Obrb','powierzchnia_lokalu', 'Kondygnacja', 'Cena_z/m2']]\n",
    "real_estates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powierzchnia_lokalu</th>\n",
       "      <th>Kondygnacja</th>\n",
       "      <th>Cena_z/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2521.000000</td>\n",
       "      <td>2152.000000</td>\n",
       "      <td>2521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.074466</td>\n",
       "      <td>3.022072</td>\n",
       "      <td>5151.744986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.453816</td>\n",
       "      <td>2.654803</td>\n",
       "      <td>1143.356914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1535.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4438.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.700000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5048.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5892.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>246.860000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9288.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       powierzchnia_lokalu  Kondygnacja   Cena_z/m2\n",
       "count          2521.000000  2152.000000  2521.000000\n",
       "mean             53.074466     3.022072  5151.744986\n",
       "std              21.453816     2.654803  1143.356914\n",
       "min              11.700000    -1.000000  1535.070000\n",
       "25%              38.100000     1.000000  4438.500000\n",
       "50%              48.700000     2.000000  5048.570000\n",
       "75%              62.600000     4.000000  5892.750000\n",
       "max             246.860000    16.000000  9288.300000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_estates.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/kinga/python/Machine_Learning/temp-plot.html'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as there is a wide range of prices, I will detect the outliers using box plot\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "data=[go.Box(y=real_estates['Cena_z/m2'], \n",
    "    boxpoints='outliers',# displays only points that are in the set, if I enter boxpoints = 'outliers', it will only show outliers\n",
    "    pointpos=0, # I determine where the points are to be located: 0-center, positive-right side, negative-left\n",
    "    jitter=1)] # I determine how much points are to be scattered (along the x-axis)\n",
    "     \n",
    "\n",
    "pyo.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot shows that outliers are below 2300 z/m2 nad above 8000 z/m2. I will remove them\n",
    "real_estates=real_estates[(real_estates['Cena_z/m2']>2300) & (real_estates['Cena_z/m2']<8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powierzchnia_lokalu</th>\n",
       "      <th>Kondygnacja</th>\n",
       "      <th>Cena_z/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2476.000000</td>\n",
       "      <td>2110.000000</td>\n",
       "      <td>2476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.009019</td>\n",
       "      <td>3.024882</td>\n",
       "      <td>5134.369083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.158942</td>\n",
       "      <td>2.671961</td>\n",
       "      <td>1065.813624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2328.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.107500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4443.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5038.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.540000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5872.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>246.860000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7978.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       powierzchnia_lokalu  Kondygnacja   Cena_z/m2\n",
       "count          2476.000000  2110.000000  2476.000000\n",
       "mean             53.009019     3.024882  5134.369083\n",
       "std              21.158942     2.671961  1065.813624\n",
       "min              11.700000    -1.000000  2328.820000\n",
       "25%              38.107500     1.000000  4443.130000\n",
       "50%              48.800000     2.000000  5038.205000\n",
       "75%              62.540000     4.000000  5872.147500\n",
       "max             246.860000    16.000000  7978.950000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_estates.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/kinga/python/Machine_Learning/temp-plot.html'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as there is a wide range of prices, I will detect the outliers using box plot\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "data=[go.Box(y=real_estates['Cena_z/m2'], \n",
    "    boxpoints='outliers',# displays only points that are in the set, if I enter boxpoints = 'outliers', it will only show outliers\n",
    "    pointpos=0, # I determine where the points are to be located: 0-center, positive-right side, negative-left\n",
    "    jitter=1)] # I determine how much points are to be scattered (along the x-axis)\n",
    "     \n",
    "\n",
    "pyo.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with NaN values\n",
    "real_estates.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>powierzchnia_lokalu</th>\n",
       "      <th>Kondygnacja</th>\n",
       "      <th>Cena_z/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2110.000000</td>\n",
       "      <td>2110.000000</td>\n",
       "      <td>2110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.798313</td>\n",
       "      <td>3.024882</td>\n",
       "      <td>5185.916938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.564385</td>\n",
       "      <td>2.671961</td>\n",
       "      <td>1074.084179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2328.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4475.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5105.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5921.522500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>228.700000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7978.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       powierzchnia_lokalu  Kondygnacja   Cena_z/m2\n",
       "count          2110.000000  2110.000000  2110.000000\n",
       "mean             52.798313     3.024882  5185.916938\n",
       "std              20.564385     2.671961  1074.084179\n",
       "min              11.700000    -1.000000  2328.820000\n",
       "25%              38.300000     1.000000  4475.107500\n",
       "50%              48.800000     2.000000  5105.500000\n",
       "75%              62.400000     4.000000  5921.522500\n",
       "max             228.700000    16.000000  7978.950000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_estates.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Features\n",
    "X=real_estates[['Obrb','powierzchnia_lokalu', 'Kondygnacja']]\n",
    "# Predicting target\n",
    "y=real_estates['Cena_z/m2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinga/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X=LabelEncoder()# object of class LabelEncoder\n",
    "X.iloc[:,0]=labelencoder_X.fit_transform(X.iloc[:,0]) #returns first column of X encoded- \n",
    "#it means that if I select first columns I will not have districts' names but numbers \n",
    "# there is a problem with this method, because ML equation will compare those values \n",
    "# To prevent from this, we are going to use OneHotEncoder\n",
    "onehotencoder=OneHotEncoder(categorical_features=[0]) #making Dummy Variables to column 'Obrb'\n",
    "X=onehotencoder.fit_transform(X).toarray() # don't have to put column number because they were specified above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting prices with Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward elimination\n",
    "import statsmodels.formula.api as sm\n",
    "# appending a column with constant value\n",
    "X=np.append(arr=np.ones((2110, 1)).astype(int), values=X, axis=1) # 2152 rows, 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the optimal matrix of features (contains only features that are statistically siginificant)\n",
    "#choosing indexes of features that are going to be considered\n",
    "X_opt=X[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29,30]] \n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.265</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   25.89</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.65e-117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:36:46</td>     <th>  Log-Likelihood:    </th> <td> -17394.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.485e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2080</td>      <th>  BIC:               </th> <td>3.502e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    29</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 7051.5096</td> <td>  355.266</td> <td>   19.849</td> <td> 0.000</td> <td> 6354.796</td> <td> 7748.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -986.7244</td> <td>  390.627</td> <td>   -2.526</td> <td> 0.012</td> <td>-1752.786</td> <td> -220.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1629.0949</td> <td>  369.169</td> <td>   -4.413</td> <td> 0.000</td> <td>-2353.074</td> <td> -905.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -788.6585</td> <td>  374.501</td> <td>   -2.106</td> <td> 0.035</td> <td>-1523.093</td> <td>  -54.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -967.4840</td> <td>  364.623</td> <td>   -2.653</td> <td> 0.008</td> <td>-1682.548</td> <td> -252.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1943.0078</td> <td>  581.237</td> <td>   -3.343</td> <td> 0.001</td> <td>-3082.875</td> <td> -803.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-2231.9381</td> <td>  495.646</td> <td>   -4.503</td> <td> 0.000</td> <td>-3203.953</td> <td>-1259.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -912.5278</td> <td>  395.031</td> <td>   -2.310</td> <td> 0.021</td> <td>-1687.226</td> <td> -137.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -855.6239</td> <td>  357.498</td> <td>   -2.393</td> <td> 0.017</td> <td>-1556.715</td> <td> -154.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -687.6020</td> <td>  372.366</td> <td>   -1.847</td> <td> 0.065</td> <td>-1417.851</td> <td>   42.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -802.9347</td> <td>  467.596</td> <td>   -1.717</td> <td> 0.086</td> <td>-1719.940</td> <td>  114.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1161.9580</td> <td>  379.024</td> <td>    3.066</td> <td> 0.002</td> <td>  418.651</td> <td> 1905.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>-1198.8129</td> <td>  642.531</td> <td>   -1.866</td> <td> 0.062</td> <td>-2458.884</td> <td>   61.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -633.6881</td> <td>  456.891</td> <td>   -1.387</td> <td> 0.166</td> <td>-1529.699</td> <td>  262.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -504.1571</td> <td>  361.379</td> <td>   -1.395</td> <td> 0.163</td> <td>-1212.859</td> <td>  204.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>-2260.5123</td> <td>  467.227</td> <td>   -4.838</td> <td> 0.000</td> <td>-3176.793</td> <td>-1344.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -592.9721</td> <td>  356.589</td> <td>   -1.663</td> <td> 0.096</td> <td>-1292.281</td> <td>  106.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -172.6331</td> <td>  516.057</td> <td>   -0.335</td> <td> 0.738</td> <td>-1184.674</td> <td>  839.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -546.9040</td> <td>  357.742</td> <td>   -1.529</td> <td> 0.126</td> <td>-1248.474</td> <td>  154.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -720.7578</td> <td>  366.082</td> <td>   -1.969</td> <td> 0.049</td> <td>-1438.682</td> <td>   -2.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>-2183.6448</td> <td>  743.313</td> <td>   -2.938</td> <td> 0.003</td> <td>-3641.359</td> <td> -725.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> -746.5731</td> <td>  457.007</td> <td>   -1.634</td> <td> 0.102</td> <td>-1642.812</td> <td>  149.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> -892.1405</td> <td>  356.036</td> <td>   -2.506</td> <td> 0.012</td> <td>-1590.365</td> <td> -193.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> -684.1611</td> <td>  357.153</td> <td>   -1.916</td> <td> 0.056</td> <td>-1384.575</td> <td>   16.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>-1197.2245</td> <td>  361.928</td> <td>   -3.308</td> <td> 0.001</td> <td>-1907.004</td> <td> -487.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>  769.0713</td> <td>  448.849</td> <td>    1.713</td> <td> 0.087</td> <td> -111.169</td> <td> 1649.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>-1065.3085</td> <td>  354.131</td> <td>   -3.008</td> <td> 0.003</td> <td>-1759.796</td> <td> -370.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>-1169.8413</td> <td>  420.382</td> <td>   -2.783</td> <td> 0.005</td> <td>-1994.254</td> <td> -345.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>  -18.2869</td> <td>    1.010</td> <td>  -18.099</td> <td> 0.000</td> <td>  -20.268</td> <td>  -16.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>  -30.7474</td> <td>    8.067</td> <td>   -3.812</td> <td> 0.000</td> <td>  -46.567</td> <td>  -14.928</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.553</td> <th>  Durbin-Watson:     </th> <td>   1.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  29.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.189</td> <th>  Prob(JB):          </th> <td>4.37e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.436</td> <th>  Cond. No.          </th> <td>5.27e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.27e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.265\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     25.89\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          2.65e-117\n",
       "Time:                        17:36:46   Log-Likelihood:                -17394.\n",
       "No. Observations:                2110   AIC:                         3.485e+04\n",
       "Df Residuals:                    2080   BIC:                         3.502e+04\n",
       "Df Model:                          29                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       7051.5096    355.266     19.849      0.000    6354.796    7748.224\n",
       "x1          -986.7244    390.627     -2.526      0.012   -1752.786    -220.663\n",
       "x2         -1629.0949    369.169     -4.413      0.000   -2353.074    -905.116\n",
       "x3          -788.6585    374.501     -2.106      0.035   -1523.093     -54.224\n",
       "x4          -967.4840    364.623     -2.653      0.008   -1682.548    -252.419\n",
       "x5         -1943.0078    581.237     -3.343      0.001   -3082.875    -803.141\n",
       "x6         -2231.9381    495.646     -4.503      0.000   -3203.953   -1259.923\n",
       "x7          -912.5278    395.031     -2.310      0.021   -1687.226    -137.830\n",
       "x8          -855.6239    357.498     -2.393      0.017   -1556.715    -154.533\n",
       "x9          -687.6020    372.366     -1.847      0.065   -1417.851      42.647\n",
       "x10         -802.9347    467.596     -1.717      0.086   -1719.940     114.071\n",
       "x11         1161.9580    379.024      3.066      0.002     418.651    1905.265\n",
       "x12        -1198.8129    642.531     -1.866      0.062   -2458.884      61.258\n",
       "x13         -633.6881    456.891     -1.387      0.166   -1529.699     262.323\n",
       "x14         -504.1571    361.379     -1.395      0.163   -1212.859     204.545\n",
       "x15        -2260.5123    467.227     -4.838      0.000   -3176.793   -1344.231\n",
       "x16         -592.9721    356.589     -1.663      0.096   -1292.281     106.337\n",
       "x17         -172.6331    516.057     -0.335      0.738   -1184.674     839.408\n",
       "x18         -546.9040    357.742     -1.529      0.126   -1248.474     154.666\n",
       "x19         -720.7578    366.082     -1.969      0.049   -1438.682      -2.833\n",
       "x20        -2183.6448    743.313     -2.938      0.003   -3641.359    -725.930\n",
       "x21         -746.5731    457.007     -1.634      0.102   -1642.812     149.666\n",
       "x22         -892.1405    356.036     -2.506      0.012   -1590.365    -193.916\n",
       "x23         -684.1611    357.153     -1.916      0.056   -1384.575      16.253\n",
       "x24        -1197.2245    361.928     -3.308      0.001   -1907.004    -487.445\n",
       "x25          769.0713    448.849      1.713      0.087    -111.169    1649.311\n",
       "x26        -1065.3085    354.131     -3.008      0.003   -1759.796    -370.821\n",
       "x27        -1169.8413    420.382     -2.783      0.005   -1994.254    -345.429\n",
       "x28          -18.2869      1.010    -18.099      0.000     -20.268     -16.305\n",
       "x29          -30.7474      8.067     -3.812      0.000     -46.567     -14.928\n",
       "==============================================================================\n",
       "Omnibus:                       24.553   Durbin-Watson:                   1.959\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.287\n",
       "Skew:                           0.189   Prob(JB):                     4.37e-07\n",
       "Kurtosis:                       3.436   Cond. No.                     5.27e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.27e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the highest P-value has x17, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,19,20,21,23,24,25,26,27,28,29,30]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.265</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   26.83</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>5.34e-118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:52:31</td>     <th>  Log-Likelihood:    </th> <td> -17394.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.485e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2081</td>      <th>  BIC:               </th> <td>3.501e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6972.5679</td> <td>  265.511</td> <td>   26.261</td> <td> 0.000</td> <td> 6451.873</td> <td> 7493.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -907.1109</td> <td>  309.692</td> <td>   -2.929</td> <td> 0.003</td> <td>-1514.450</td> <td> -299.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1549.5987</td> <td>  282.451</td> <td>   -5.486</td> <td> 0.000</td> <td>-2103.515</td> <td> -995.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -709.0932</td> <td>  289.213</td> <td>   -2.452</td> <td> 0.014</td> <td>-1276.269</td> <td> -141.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -887.9943</td> <td>  276.503</td> <td>   -3.212</td> <td> 0.001</td> <td>-1430.246</td> <td> -345.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1863.2650</td> <td>  529.993</td> <td>   -3.516</td> <td> 0.000</td> <td>-2902.637</td> <td> -823.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-2152.4124</td> <td>  434.822</td> <td>   -4.950</td> <td> 0.000</td> <td>-3005.143</td> <td>-1299.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -833.0710</td> <td>  315.579</td> <td>   -2.640</td> <td> 0.008</td> <td>-1451.955</td> <td> -214.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -776.0451</td> <td>  266.803</td> <td>   -2.909</td> <td> 0.004</td> <td>-1299.275</td> <td> -252.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -608.0925</td> <td>  286.583</td> <td>   -2.122</td> <td> 0.034</td> <td>-1170.111</td> <td>  -46.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -723.1363</td> <td>  402.087</td> <td>   -1.798</td> <td> 0.072</td> <td>-1511.671</td> <td>   65.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1241.5436</td> <td>  294.996</td> <td>    4.209</td> <td> 0.000</td> <td>  663.026</td> <td> 1820.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>-1118.5629</td> <td>  595.941</td> <td>   -1.877</td> <td> 0.061</td> <td>-2287.265</td> <td>   50.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -554.0490</td> <td>  389.883</td> <td>   -1.421</td> <td> 0.155</td> <td>-1318.650</td> <td>  210.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -424.5651</td> <td>  271.945</td> <td>   -1.561</td> <td> 0.119</td> <td> -957.878</td> <td>  108.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>-2180.9461</td> <td>  402.069</td> <td>   -5.424</td> <td> 0.000</td> <td>-2969.446</td> <td>-1392.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -513.3816</td> <td>  265.554</td> <td>   -1.933</td> <td> 0.053</td> <td>-1034.161</td> <td>    7.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -467.2759</td> <td>  266.999</td> <td>   -1.750</td> <td> 0.080</td> <td> -990.889</td> <td>   56.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -641.2285</td> <td>  278.321</td> <td>   -2.304</td> <td> 0.021</td> <td>-1187.046</td> <td>  -95.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>-2104.0812</td> <td>  704.084</td> <td>   -2.988</td> <td> 0.003</td> <td>-3484.863</td> <td> -723.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -667.0658</td> <td>  390.259</td> <td>   -1.709</td> <td> 0.088</td> <td>-1432.404</td> <td>   98.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> -812.5948</td> <td>  264.932</td> <td>   -3.067</td> <td> 0.002</td> <td>-1332.153</td> <td> -293.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> -604.6164</td> <td>  266.432</td> <td>   -2.269</td> <td> 0.023</td> <td>-1127.117</td> <td>  -82.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>-1117.5875</td> <td>  272.557</td> <td>   -4.100</td> <td> 0.000</td> <td>-1652.100</td> <td> -583.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>  848.6571</td> <td>  380.531</td> <td>    2.230</td> <td> 0.026</td> <td>  102.397</td> <td> 1594.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td> -985.7467</td> <td>  262.323</td> <td>   -3.758</td> <td> 0.000</td> <td>-1500.189</td> <td> -471.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>-1090.3310</td> <td>  346.665</td> <td>   -3.145</td> <td> 0.002</td> <td>-1770.177</td> <td> -410.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>  -18.2981</td> <td>    1.010</td> <td>  -18.124</td> <td> 0.000</td> <td>  -20.278</td> <td>  -16.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>  -30.7601</td> <td>    8.065</td> <td>   -3.814</td> <td> 0.000</td> <td>  -46.576</td> <td>  -14.944</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.549</td> <th>  Durbin-Watson:     </th> <td>   1.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  29.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.189</td> <th>  Prob(JB):          </th> <td>4.38e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.436</td> <th>  Cond. No.          </th> <td>3.84e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.84e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.265\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     26.83\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          5.34e-118\n",
       "Time:                        17:52:31   Log-Likelihood:                -17394.\n",
       "No. Observations:                2110   AIC:                         3.485e+04\n",
       "Df Residuals:                    2081   BIC:                         3.501e+04\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6972.5679    265.511     26.261      0.000    6451.873    7493.263\n",
       "x1          -907.1109    309.692     -2.929      0.003   -1514.450    -299.772\n",
       "x2         -1549.5987    282.451     -5.486      0.000   -2103.515    -995.682\n",
       "x3          -709.0932    289.213     -2.452      0.014   -1276.269    -141.917\n",
       "x4          -887.9943    276.503     -3.212      0.001   -1430.246    -345.743\n",
       "x5         -1863.2650    529.993     -3.516      0.000   -2902.637    -823.892\n",
       "x6         -2152.4124    434.822     -4.950      0.000   -3005.143   -1299.682\n",
       "x7          -833.0710    315.579     -2.640      0.008   -1451.955    -214.187\n",
       "x8          -776.0451    266.803     -2.909      0.004   -1299.275    -252.816\n",
       "x9          -608.0925    286.583     -2.122      0.034   -1170.111     -46.074\n",
       "x10         -723.1363    402.087     -1.798      0.072   -1511.671      65.399\n",
       "x11         1241.5436    294.996      4.209      0.000     663.026    1820.062\n",
       "x12        -1118.5629    595.941     -1.877      0.061   -2287.265      50.139\n",
       "x13         -554.0490    389.883     -1.421      0.155   -1318.650     210.552\n",
       "x14         -424.5651    271.945     -1.561      0.119    -957.878     108.748\n",
       "x15        -2180.9461    402.069     -5.424      0.000   -2969.446   -1392.446\n",
       "x16         -513.3816    265.554     -1.933      0.053   -1034.161       7.397\n",
       "x17         -467.2759    266.999     -1.750      0.080    -990.889      56.338\n",
       "x18         -641.2285    278.321     -2.304      0.021   -1187.046     -95.411\n",
       "x19        -2104.0812    704.084     -2.988      0.003   -3484.863    -723.299\n",
       "x20         -667.0658    390.259     -1.709      0.088   -1432.404      98.272\n",
       "x21         -812.5948    264.932     -3.067      0.002   -1332.153    -293.036\n",
       "x22         -604.6164    266.432     -2.269      0.023   -1127.117     -82.116\n",
       "x23        -1117.5875    272.557     -4.100      0.000   -1652.100    -583.075\n",
       "x24          848.6571    380.531      2.230      0.026     102.397    1594.917\n",
       "x25         -985.7467    262.323     -3.758      0.000   -1500.189    -471.305\n",
       "x26        -1090.3310    346.665     -3.145      0.002   -1770.177    -410.485\n",
       "x27          -18.2981      1.010    -18.124      0.000     -20.278     -16.318\n",
       "x28          -30.7601      8.065     -3.814      0.000     -46.576     -14.944\n",
       "==============================================================================\n",
       "Omnibus:                       24.549   Durbin-Watson:                   1.959\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.282\n",
       "Skew:                           0.189   Prob(JB):                     4.38e-07\n",
       "Kurtosis:                       3.436   Cond. No.                     3.84e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.84e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.265</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.73</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.66e-118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:52:58</td>     <th>  Log-Likelihood:    </th> <td> -17396.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.485e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2082</td>      <th>  BIC:               </th> <td>3.501e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    27</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6730.8541</td> <td>  203.923</td> <td>   33.007</td> <td> 0.000</td> <td> 6330.939</td> <td> 7130.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -666.4175</td> <td>  259.334</td> <td>   -2.570</td> <td> 0.010</td> <td>-1174.999</td> <td> -157.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1308.6347</td> <td>  225.945</td> <td>   -5.792</td> <td> 0.000</td> <td>-1751.736</td> <td> -865.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -468.2214</td> <td>  234.393</td> <td>   -1.998</td> <td> 0.046</td> <td> -927.891</td> <td>   -8.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -647.0473</td> <td>  218.469</td> <td>   -2.962</td> <td> 0.003</td> <td>-1075.488</td> <td> -218.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1622.4791</td> <td>  502.301</td> <td>   -3.230</td> <td> 0.001</td> <td>-2607.544</td> <td> -637.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1911.4380</td> <td>  400.491</td> <td>   -4.773</td> <td> 0.000</td> <td>-2696.844</td> <td>-1126.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -592.0187</td> <td>  266.179</td> <td>   -2.224</td> <td> 0.026</td> <td>-1114.024</td> <td>  -70.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -535.1541</td> <td>  206.082</td> <td>   -2.597</td> <td> 0.009</td> <td> -939.302</td> <td> -131.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -367.1398</td> <td>  231.097</td> <td>   -1.589</td> <td> 0.112</td> <td> -820.346</td> <td>   86.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -482.4339</td> <td>  364.759</td> <td>   -1.323</td> <td> 0.186</td> <td>-1197.764</td> <td>  232.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1482.3658</td> <td>  241.521</td> <td>    6.138</td> <td> 0.000</td> <td> 1008.718</td> <td> 1956.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -878.3042</td> <td>  571.595</td> <td>   -1.537</td> <td> 0.125</td> <td>-1999.262</td> <td>  242.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -183.6647</td> <td>  212.695</td> <td>   -0.864</td> <td> 0.388</td> <td> -600.781</td> <td>  233.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>-1939.9892</td> <td>  364.656</td> <td>   -5.320</td> <td> 0.000</td> <td>-2655.118</td> <td>-1224.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -272.5547</td> <td>  204.498</td> <td>   -1.333</td> <td> 0.183</td> <td> -673.597</td> <td>  128.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -226.4540</td> <td>  206.375</td> <td>   -1.097</td> <td> 0.273</td> <td> -631.178</td> <td>  178.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -400.3514</td> <td>  220.805</td> <td>   -1.813</td> <td> 0.070</td> <td> -833.373</td> <td>   32.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>-1863.0894</td> <td>  683.523</td> <td>   -2.726</td> <td> 0.006</td> <td>-3203.549</td> <td> -522.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -426.0719</td> <td>  351.572</td> <td>   -1.212</td> <td> 0.226</td> <td>-1115.540</td> <td>  263.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -571.6686</td> <td>  203.631</td> <td>   -2.807</td> <td> 0.005</td> <td> -971.010</td> <td> -172.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> -363.8028</td> <td>  205.645</td> <td>   -1.769</td> <td> 0.077</td> <td> -767.094</td> <td>   39.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> -876.9134</td> <td>  213.603</td> <td>   -4.105</td> <td> 0.000</td> <td>-1295.811</td> <td> -458.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> 1089.4568</td> <td>  340.803</td> <td>    3.197</td> <td> 0.001</td> <td>  421.106</td> <td> 1757.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td> -744.8338</td> <td>  200.231</td> <td>   -3.720</td> <td> 0.000</td> <td>-1137.508</td> <td> -352.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td> -849.3728</td> <td>  302.440</td> <td>   -2.808</td> <td> 0.005</td> <td>-1442.490</td> <td> -256.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>  -18.2861</td> <td>    1.010</td> <td>  -18.108</td> <td> 0.000</td> <td>  -20.267</td> <td>  -16.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>  -30.6886</td> <td>    8.067</td> <td>   -3.804</td> <td> 0.000</td> <td>  -46.508</td> <td>  -14.869</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.292</td> <th>  Durbin-Watson:     </th> <td>   1.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.189</td> <th>  Prob(JB):          </th> <td>5.37e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.431</td> <th>  Cond. No.          </th> <td>2.89e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.89e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.265\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     27.73\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          2.66e-118\n",
       "Time:                        17:52:58   Log-Likelihood:                -17396.\n",
       "No. Observations:                2110   AIC:                         3.485e+04\n",
       "Df Residuals:                    2082   BIC:                         3.501e+04\n",
       "Df Model:                          27                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6730.8541    203.923     33.007      0.000    6330.939    7130.769\n",
       "x1          -666.4175    259.334     -2.570      0.010   -1174.999    -157.836\n",
       "x2         -1308.6347    225.945     -5.792      0.000   -1751.736    -865.533\n",
       "x3          -468.2214    234.393     -1.998      0.046    -927.891      -8.552\n",
       "x4          -647.0473    218.469     -2.962      0.003   -1075.488    -218.606\n",
       "x5         -1622.4791    502.301     -3.230      0.001   -2607.544    -637.414\n",
       "x6         -1911.4380    400.491     -4.773      0.000   -2696.844   -1126.033\n",
       "x7          -592.0187    266.179     -2.224      0.026   -1114.024     -70.013\n",
       "x8          -535.1541    206.082     -2.597      0.009    -939.302    -131.006\n",
       "x9          -367.1398    231.097     -1.589      0.112    -820.346      86.066\n",
       "x10         -482.4339    364.759     -1.323      0.186   -1197.764     232.896\n",
       "x11         1482.3658    241.521      6.138      0.000    1008.718    1956.014\n",
       "x12         -878.3042    571.595     -1.537      0.125   -1999.262     242.653\n",
       "x13         -183.6647    212.695     -0.864      0.388    -600.781     233.452\n",
       "x14        -1939.9892    364.656     -5.320      0.000   -2655.118   -1224.861\n",
       "x15         -272.5547    204.498     -1.333      0.183    -673.597     128.488\n",
       "x16         -226.4540    206.375     -1.097      0.273    -631.178     178.270\n",
       "x17         -400.3514    220.805     -1.813      0.070    -833.373      32.670\n",
       "x18        -1863.0894    683.523     -2.726      0.006   -3203.549    -522.630\n",
       "x19         -426.0719    351.572     -1.212      0.226   -1115.540     263.397\n",
       "x20         -571.6686    203.631     -2.807      0.005    -971.010    -172.327\n",
       "x21         -363.8028    205.645     -1.769      0.077    -767.094      39.489\n",
       "x22         -876.9134    213.603     -4.105      0.000   -1295.811    -458.016\n",
       "x23         1089.4568    340.803      3.197      0.001     421.106    1757.808\n",
       "x24         -744.8338    200.231     -3.720      0.000   -1137.508    -352.160\n",
       "x25         -849.3728    302.440     -2.808      0.005   -1442.490    -256.256\n",
       "x26          -18.2861      1.010    -18.108      0.000     -20.267     -16.306\n",
       "x27          -30.6886      8.067     -3.804      0.000     -46.508     -14.869\n",
       "==============================================================================\n",
       "Omnibus:                       24.292   Durbin-Watson:                   1.956\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.873\n",
       "Skew:                           0.189   Prob(JB):                     5.37e-07\n",
       "Kurtosis:                       3.431   Cond. No.                     2.89e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.89e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x13, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,14,15,16,18,19,20,21,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.264</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.77</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>7.02e-119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:53:30</td>     <th>  Log-Likelihood:    </th> <td> -17396.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.485e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2083</td>      <th>  BIC:               </th> <td>3.500e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    26</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6577.6080</td> <td>  100.442</td> <td>   65.487</td> <td> 0.000</td> <td> 6380.631</td> <td> 6774.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -513.2699</td> <td>  189.197</td> <td>   -2.713</td> <td> 0.007</td> <td> -884.304</td> <td> -142.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1155.9594</td> <td>  140.670</td> <td>   -8.218</td> <td> 0.000</td> <td>-1431.827</td> <td> -880.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -315.6240</td> <td>  153.976</td> <td>   -2.050</td> <td> 0.041</td> <td> -617.586</td> <td>  -13.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -494.2286</td> <td>  128.091</td> <td>   -3.858</td> <td> 0.000</td> <td> -745.429</td> <td> -243.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1470.8804</td> <td>  470.593</td> <td>   -3.126</td> <td> 0.002</td> <td>-2393.762</td> <td> -547.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1759.0589</td> <td>  359.497</td> <td>   -4.893</td> <td> 0.000</td> <td>-2464.070</td> <td>-1054.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -439.4887</td> <td>  199.111</td> <td>   -2.207</td> <td> 0.027</td> <td> -829.967</td> <td>  -49.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -382.7686</td> <td>  106.425</td> <td>   -3.597</td> <td> 0.000</td> <td> -591.479</td> <td> -174.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -214.5137</td> <td>  148.871</td> <td>   -1.441</td> <td> 0.150</td> <td> -506.465</td> <td>   77.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -330.8484</td> <td>  319.720</td> <td>   -1.035</td> <td> 0.301</td> <td> -957.852</td> <td>  296.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1635.0603</td> <td>  164.501</td> <td>    9.940</td> <td> 0.000</td> <td> 1312.457</td> <td> 1957.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -728.0677</td> <td>  544.440</td> <td>   -1.337</td> <td> 0.181</td> <td>-1795.770</td> <td>  339.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>-1787.8491</td> <td>  319.248</td> <td>   -5.600</td> <td> 0.000</td> <td>-2413.928</td> <td>-1161.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -119.9259</td> <td>  102.842</td> <td>   -1.166</td> <td> 0.244</td> <td> -321.610</td> <td>   81.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>  -74.1063</td> <td>  107.064</td> <td>   -0.692</td> <td> 0.489</td> <td> -284.070</td> <td>  135.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -247.4873</td> <td>  131.964</td> <td>   -1.875</td> <td> 0.061</td> <td> -506.283</td> <td>   11.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>-1711.1129</td> <td>  660.435</td> <td>   -2.591</td> <td> 0.010</td> <td>-3006.295</td> <td> -415.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -273.6464</td> <td>  304.028</td> <td>   -0.900</td> <td> 0.368</td> <td> -869.876</td> <td>  322.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -419.1987</td> <td>  101.428</td> <td>   -4.133</td> <td> 0.000</td> <td> -618.109</td> <td> -220.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -210.7285</td> <td>  104.232</td> <td>   -2.022</td> <td> 0.043</td> <td> -415.138</td> <td>   -6.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> -723.8563</td> <td>  119.194</td> <td>   -6.073</td> <td> 0.000</td> <td> -957.608</td> <td> -490.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> 1242.2688</td> <td>  291.238</td> <td>    4.265</td> <td> 0.000</td> <td>  671.120</td> <td> 1813.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> -592.4250</td> <td>   94.550</td> <td>   -6.266</td> <td> 0.000</td> <td> -777.847</td> <td> -407.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td> -696.7822</td> <td>  245.432</td> <td>   -2.839</td> <td> 0.005</td> <td>-1178.100</td> <td> -215.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>  -18.2579</td> <td>    1.009</td> <td>  -18.091</td> <td> 0.000</td> <td>  -20.237</td> <td>  -16.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>  -30.9629</td> <td>    8.060</td> <td>   -3.842</td> <td> 0.000</td> <td>  -46.769</td> <td>  -15.157</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.005</td> <th>  Durbin-Watson:     </th> <td>   1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.188</td> <th>  Prob(JB):          </th> <td>6.51e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.428</td> <th>  Cond. No.          </th> <td>1.87e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.87e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.264\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     28.77\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          7.02e-119\n",
       "Time:                        17:53:30   Log-Likelihood:                -17396.\n",
       "No. Observations:                2110   AIC:                         3.485e+04\n",
       "Df Residuals:                    2083   BIC:                         3.500e+04\n",
       "Df Model:                          26                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6577.6080    100.442     65.487      0.000    6380.631    6774.585\n",
       "x1          -513.2699    189.197     -2.713      0.007    -884.304    -142.236\n",
       "x2         -1155.9594    140.670     -8.218      0.000   -1431.827    -880.092\n",
       "x3          -315.6240    153.976     -2.050      0.041    -617.586     -13.662\n",
       "x4          -494.2286    128.091     -3.858      0.000    -745.429    -243.029\n",
       "x5         -1470.8804    470.593     -3.126      0.002   -2393.762    -547.998\n",
       "x6         -1759.0589    359.497     -4.893      0.000   -2464.070   -1054.048\n",
       "x7          -439.4887    199.111     -2.207      0.027    -829.967     -49.011\n",
       "x8          -382.7686    106.425     -3.597      0.000    -591.479    -174.059\n",
       "x9          -214.5137    148.871     -1.441      0.150    -506.465      77.438\n",
       "x10         -330.8484    319.720     -1.035      0.301    -957.852     296.155\n",
       "x11         1635.0603    164.501      9.940      0.000    1312.457    1957.664\n",
       "x12         -728.0677    544.440     -1.337      0.181   -1795.770     339.635\n",
       "x13        -1787.8491    319.248     -5.600      0.000   -2413.928   -1161.770\n",
       "x14         -119.9259    102.842     -1.166      0.244    -321.610      81.758\n",
       "x15          -74.1063    107.064     -0.692      0.489    -284.070     135.857\n",
       "x16         -247.4873    131.964     -1.875      0.061    -506.283      11.308\n",
       "x17        -1711.1129    660.435     -2.591      0.010   -3006.295    -415.931\n",
       "x18         -273.6464    304.028     -0.900      0.368    -869.876     322.583\n",
       "x19         -419.1987    101.428     -4.133      0.000    -618.109    -220.288\n",
       "x20         -210.7285    104.232     -2.022      0.043    -415.138      -6.319\n",
       "x21         -723.8563    119.194     -6.073      0.000    -957.608    -490.105\n",
       "x22         1242.2688    291.238      4.265      0.000     671.120    1813.418\n",
       "x23         -592.4250     94.550     -6.266      0.000    -777.847    -407.003\n",
       "x24         -696.7822    245.432     -2.839      0.005   -1178.100    -215.465\n",
       "x25          -18.2579      1.009    -18.091      0.000     -20.237     -16.279\n",
       "x26          -30.9629      8.060     -3.842      0.000     -46.769     -15.157\n",
       "==============================================================================\n",
       "Omnibus:                       24.005   Durbin-Watson:                   1.955\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.489\n",
       "Skew:                           0.188   Prob(JB):                     6.51e-07\n",
       "Kurtosis:                       3.428   Cond. No.                     1.87e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.87e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x13, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,15,16,18,19,20,21,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.264</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.91</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>1.60e-119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:11</td>     <th>  Log-Likelihood:    </th> <td> -17396.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2084</td>      <th>  BIC:               </th> <td>3.499e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    25</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6537.4593</td> <td>   81.990</td> <td>   79.734</td> <td> 0.000</td> <td> 6376.668</td> <td> 6698.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -470.5826</td> <td>  178.841</td> <td>   -2.631</td> <td> 0.009</td> <td> -821.308</td> <td> -119.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1114.2911</td> <td>  127.122</td> <td>   -8.766</td> <td> 0.000</td> <td>-1363.590</td> <td> -864.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -273.7745</td> <td>  141.591</td> <td>   -1.934</td> <td> 0.053</td> <td> -551.448</td> <td>    3.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -452.4176</td> <td>  112.939</td> <td>   -4.006</td> <td> 0.000</td> <td> -673.903</td> <td> -230.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1429.5044</td> <td>  466.723</td> <td>   -3.063</td> <td> 0.002</td> <td>-2344.796</td> <td> -514.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1717.6230</td> <td>  354.433</td> <td>   -4.846</td> <td> 0.000</td> <td>-2412.703</td> <td>-1022.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -398.1472</td> <td>  189.918</td> <td>   -2.096</td> <td> 0.036</td> <td> -770.596</td> <td>  -25.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -341.1151</td> <td>   87.766</td> <td>   -3.887</td> <td> 0.000</td> <td> -513.233</td> <td> -168.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -172.8506</td> <td>  136.143</td> <td>   -1.270</td> <td> 0.204</td> <td> -439.841</td> <td>   94.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -289.2683</td> <td>  313.986</td> <td>   -0.921</td> <td> 0.357</td> <td> -905.027</td> <td>  326.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1677.1039</td> <td>  152.857</td> <td>   10.972</td> <td> 0.000</td> <td> 1377.336</td> <td> 1976.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -686.2904</td> <td>  541.016</td> <td>   -1.269</td> <td> 0.205</td> <td>-1747.279</td> <td>  374.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>-1746.5342</td> <td>  313.580</td> <td>   -5.570</td> <td> 0.000</td> <td>-2361.496</td> <td>-1131.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>  -77.9400</td> <td>   83.038</td> <td>   -0.939</td> <td> 0.348</td> <td> -240.786</td> <td>   84.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -205.4661</td> <td>  117.156</td> <td>   -1.754</td> <td> 0.080</td> <td> -435.221</td> <td>   24.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>-1670.0009</td> <td>  657.677</td> <td>   -2.539</td> <td> 0.011</td> <td>-2959.773</td> <td> -380.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -232.2281</td> <td>  298.043</td> <td>   -0.779</td> <td> 0.436</td> <td> -816.722</td> <td>  352.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -377.5766</td> <td>   81.670</td> <td>   -4.623</td> <td> 0.000</td> <td> -537.740</td> <td> -217.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -168.3990</td> <td>   84.395</td> <td>   -1.995</td> <td> 0.046</td> <td> -333.907</td> <td>   -2.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -681.1827</td> <td>  101.998</td> <td>   -6.678</td> <td> 0.000</td> <td> -881.211</td> <td> -481.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> 1284.4516</td> <td>  284.755</td> <td>    4.511</td> <td> 0.000</td> <td>  726.017</td> <td> 1842.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> -550.8113</td> <td>   72.965</td> <td>   -7.549</td> <td> 0.000</td> <td> -693.902</td> <td> -407.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> -655.1583</td> <td>  237.921</td> <td>   -2.754</td> <td> 0.006</td> <td>-1121.746</td> <td> -188.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>  -18.2687</td> <td>    1.009</td> <td>  -18.106</td> <td> 0.000</td> <td>  -20.247</td> <td>  -16.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>  -31.3359</td> <td>    8.041</td> <td>   -3.897</td> <td> 0.000</td> <td>  -47.105</td> <td>  -15.567</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>23.612</td> <th>  Durbin-Watson:     </th> <td>   1.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.184</td> <th>  Prob(JB):          </th> <td>7.60e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.431</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.264\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     29.91\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          1.60e-119\n",
       "Time:                        17:54:11   Log-Likelihood:                -17396.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2084   BIC:                         3.499e+04\n",
       "Df Model:                          25                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6537.4593     81.990     79.734      0.000    6376.668    6698.251\n",
       "x1          -470.5826    178.841     -2.631      0.009    -821.308    -119.858\n",
       "x2         -1114.2911    127.122     -8.766      0.000   -1363.590    -864.993\n",
       "x3          -273.7745    141.591     -1.934      0.053    -551.448       3.899\n",
       "x4          -452.4176    112.939     -4.006      0.000    -673.903    -230.932\n",
       "x5         -1429.5044    466.723     -3.063      0.002   -2344.796    -514.213\n",
       "x6         -1717.6230    354.433     -4.846      0.000   -2412.703   -1022.543\n",
       "x7          -398.1472    189.918     -2.096      0.036    -770.596     -25.698\n",
       "x8          -341.1151     87.766     -3.887      0.000    -513.233    -168.997\n",
       "x9          -172.8506    136.143     -1.270      0.204    -439.841      94.140\n",
       "x10         -289.2683    313.986     -0.921      0.357    -905.027     326.491\n",
       "x11         1677.1039    152.857     10.972      0.000    1377.336    1976.871\n",
       "x12         -686.2904    541.016     -1.269      0.205   -1747.279     374.698\n",
       "x13        -1746.5342    313.580     -5.570      0.000   -2361.496   -1131.572\n",
       "x14          -77.9400     83.038     -0.939      0.348    -240.786      84.906\n",
       "x15         -205.4661    117.156     -1.754      0.080    -435.221      24.289\n",
       "x16        -1670.0009    657.677     -2.539      0.011   -2959.773    -380.229\n",
       "x17         -232.2281    298.043     -0.779      0.436    -816.722     352.266\n",
       "x18         -377.5766     81.670     -4.623      0.000    -537.740    -217.413\n",
       "x19         -168.3990     84.395     -1.995      0.046    -333.907      -2.891\n",
       "x20         -681.1827    101.998     -6.678      0.000    -881.211    -481.154\n",
       "x21         1284.4516    284.755      4.511      0.000     726.017    1842.886\n",
       "x22         -550.8113     72.965     -7.549      0.000    -693.902    -407.720\n",
       "x23         -655.1583    237.921     -2.754      0.006   -1121.746    -188.571\n",
       "x24          -18.2687      1.009    -18.106      0.000     -20.247     -16.290\n",
       "x25          -31.3359      8.041     -3.897      0.000     -47.105     -15.567\n",
       "==============================================================================\n",
       "Omnibus:                       23.612   Durbin-Watson:                   1.954\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.181\n",
       "Skew:                           0.184   Prob(JB):                     7.60e-07\n",
       "Kurtosis:                       3.431   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x15, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,15,16,19,20,21,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.264</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>3.80e-120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:52</td>     <th>  Log-Likelihood:    </th> <td> -17396.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2085</td>      <th>  BIC:               </th> <td>3.498e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6528.4596</td> <td>   81.165</td> <td>   80.434</td> <td> 0.000</td> <td> 6369.287</td> <td> 6687.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -463.3609</td> <td>  178.584</td> <td>   -2.595</td> <td> 0.010</td> <td> -813.582</td> <td> -113.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1106.6881</td> <td>  126.735</td> <td>   -8.732</td> <td> 0.000</td> <td>-1355.228</td> <td> -858.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -266.3444</td> <td>  141.256</td> <td>   -1.886</td> <td> 0.059</td> <td> -543.362</td> <td>   10.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -444.8179</td> <td>  112.507</td> <td>   -3.954</td> <td> 0.000</td> <td> -665.455</td> <td> -224.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1422.4032</td> <td>  466.590</td> <td>   -3.049</td> <td> 0.002</td> <td>-2337.434</td> <td> -507.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1710.0555</td> <td>  354.267</td> <td>   -4.827</td> <td> 0.000</td> <td>-2404.809</td> <td>-1015.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -390.4180</td> <td>  189.641</td> <td>   -2.059</td> <td> 0.040</td> <td> -762.324</td> <td>  -18.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -333.6904</td> <td>   87.239</td> <td>   -3.825</td> <td> 0.000</td> <td> -504.775</td> <td> -162.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -165.2760</td> <td>  135.783</td> <td>   -1.217</td> <td> 0.224</td> <td> -431.560</td> <td>  101.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -282.3135</td> <td>  313.830</td> <td>   -0.900</td> <td> 0.368</td> <td> -897.766</td> <td>  333.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1684.4660</td> <td>  152.550</td> <td>   11.042</td> <td> 0.000</td> <td> 1385.300</td> <td> 1983.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -680.3448</td> <td>  540.911</td> <td>   -1.258</td> <td> 0.209</td> <td>-1741.127</td> <td>  380.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>-1739.0402</td> <td>  313.403</td> <td>   -5.549</td> <td> 0.000</td> <td>-2353.655</td> <td>-1124.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>  -70.5817</td> <td>   82.492</td> <td>   -0.856</td> <td> 0.392</td> <td> -232.356</td> <td>   91.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -197.9787</td> <td>  116.750</td> <td>   -1.696</td> <td> 0.090</td> <td> -426.938</td> <td>   30.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>-1662.4761</td> <td>  657.544</td> <td>   -2.528</td> <td> 0.012</td> <td>-2951.987</td> <td> -372.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -370.0758</td> <td>   81.093</td> <td>   -4.564</td> <td> 0.000</td> <td> -529.108</td> <td> -211.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -160.9833</td> <td>   83.849</td> <td>   -1.920</td> <td> 0.055</td> <td> -325.420</td> <td>    3.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -674.0105</td> <td>  101.572</td> <td>   -6.636</td> <td> 0.000</td> <td> -873.204</td> <td> -474.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> 1291.7961</td> <td>  284.572</td> <td>    4.539</td> <td> 0.000</td> <td>  733.721</td> <td> 1849.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> -543.3446</td> <td>   72.326</td> <td>   -7.512</td> <td> 0.000</td> <td> -685.183</td> <td> -401.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> -647.5804</td> <td>  237.700</td> <td>   -2.724</td> <td> 0.006</td> <td>-1113.734</td> <td> -181.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>  -18.2430</td> <td>    1.008</td> <td>  -18.092</td> <td> 0.000</td> <td>  -20.221</td> <td>  -16.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>  -31.2622</td> <td>    8.040</td> <td>   -3.889</td> <td> 0.000</td> <td>  -47.029</td> <td>  -15.496</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>23.645</td> <th>  Durbin-Watson:     </th> <td>   1.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.185</td> <th>  Prob(JB):          </th> <td>7.74e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.429</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.264\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     31.14\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          3.80e-120\n",
       "Time:                        17:54:52   Log-Likelihood:                -17396.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2085   BIC:                         3.498e+04\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6528.4596     81.165     80.434      0.000    6369.287    6687.633\n",
       "x1          -463.3609    178.584     -2.595      0.010    -813.582    -113.140\n",
       "x2         -1106.6881    126.735     -8.732      0.000   -1355.228    -858.149\n",
       "x3          -266.3444    141.256     -1.886      0.059    -543.362      10.673\n",
       "x4          -444.8179    112.507     -3.954      0.000    -665.455    -224.181\n",
       "x5         -1422.4032    466.590     -3.049      0.002   -2337.434    -507.373\n",
       "x6         -1710.0555    354.267     -4.827      0.000   -2404.809   -1015.302\n",
       "x7          -390.4180    189.641     -2.059      0.040    -762.324     -18.512\n",
       "x8          -333.6904     87.239     -3.825      0.000    -504.775    -162.606\n",
       "x9          -165.2760    135.783     -1.217      0.224    -431.560     101.008\n",
       "x10         -282.3135    313.830     -0.900      0.368    -897.766     333.138\n",
       "x11         1684.4660    152.550     11.042      0.000    1385.300    1983.632\n",
       "x12         -680.3448    540.911     -1.258      0.209   -1741.127     380.438\n",
       "x13        -1739.0402    313.403     -5.549      0.000   -2353.655   -1124.426\n",
       "x14          -70.5817     82.492     -0.856      0.392    -232.356      91.193\n",
       "x15         -197.9787    116.750     -1.696      0.090    -426.938      30.980\n",
       "x16        -1662.4761    657.544     -2.528      0.012   -2951.987    -372.965\n",
       "x17         -370.0758     81.093     -4.564      0.000    -529.108    -211.044\n",
       "x18         -160.9833     83.849     -1.920      0.055    -325.420       3.453\n",
       "x19         -674.0105    101.572     -6.636      0.000    -873.204    -474.817\n",
       "x20         1291.7961    284.572      4.539      0.000     733.721    1849.872\n",
       "x21         -543.3446     72.326     -7.512      0.000    -685.183    -401.506\n",
       "x22         -647.5804    237.700     -2.724      0.006   -1113.734    -181.427\n",
       "x23          -18.2430      1.008    -18.092      0.000     -20.221     -16.266\n",
       "x24          -31.2622      8.040     -3.889      0.000     -47.029     -15.496\n",
       "==============================================================================\n",
       "Omnibus:                       23.645   Durbin-Watson:                   1.954\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.144\n",
       "Skew:                           0.185   Prob(JB):                     7.74e-07\n",
       "Kurtosis:                       3.429   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x17, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,15,16,19,20,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the highest P-value has x14, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,10,11,12,15,19,20,23,24,25,26,27,28,29,30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.264</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.47</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>9.40e-121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:55:29</td>     <th>  Log-Likelihood:    </th> <td> -17397.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2086</td>      <th>  BIC:               </th> <td>3.498e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6500.1412</td> <td>   74.106</td> <td>   87.714</td> <td> 0.000</td> <td> 6354.812</td> <td> 6645.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -433.1803</td> <td>  175.054</td> <td>   -2.475</td> <td> 0.013</td> <td> -776.479</td> <td>  -89.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1077.9300</td> <td>  122.189</td> <td>   -8.822</td> <td> 0.000</td> <td>-1317.554</td> <td> -838.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -237.5470</td> <td>  137.179</td> <td>   -1.732</td> <td> 0.083</td> <td> -506.569</td> <td>   31.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -415.7589</td> <td>  107.251</td> <td>   -3.876</td> <td> 0.000</td> <td> -626.090</td> <td> -205.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1395.2945</td> <td>  465.483</td> <td>   -2.998</td> <td> 0.003</td> <td>-2308.154</td> <td> -482.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1681.8704</td> <td>  352.709</td> <td>   -4.768</td> <td> 0.000</td> <td>-2373.569</td> <td> -990.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -362.1080</td> <td>  186.720</td> <td>   -1.939</td> <td> 0.053</td> <td> -728.286</td> <td>    4.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -305.3262</td> <td>   80.690</td> <td>   -3.784</td> <td> 0.000</td> <td> -463.567</td> <td> -147.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -136.5869</td> <td>  131.569</td> <td>   -1.038</td> <td> 0.299</td> <td> -394.607</td> <td>  121.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -255.0621</td> <td>  312.189</td> <td>   -0.817</td> <td> 0.414</td> <td> -867.297</td> <td>  357.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 1713.5438</td> <td>  148.707</td> <td>   11.523</td> <td> 0.000</td> <td> 1421.915</td> <td> 2005.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -654.7178</td> <td>  540.047</td> <td>   -1.212</td> <td> 0.226</td> <td>-1713.805</td> <td>  404.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>-1711.2653</td> <td>  311.697</td> <td>   -5.490</td> <td> 0.000</td> <td>-2322.535</td> <td>-1099.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -168.6948</td> <td>  111.614</td> <td>   -1.511</td> <td> 0.131</td> <td> -387.581</td> <td>   50.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>-1635.0762</td> <td>  656.722</td> <td>   -2.490</td> <td> 0.013</td> <td>-2922.974</td> <td> -347.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -341.6249</td> <td>   73.957</td> <td>   -4.619</td> <td> 0.000</td> <td> -486.663</td> <td> -196.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -131.1802</td> <td>   76.267</td> <td>   -1.720</td> <td> 0.086</td> <td> -280.747</td> <td>   18.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -643.9601</td> <td>   95.301</td> <td>   -6.757</td> <td> 0.000</td> <td> -830.855</td> <td> -457.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> 1321.1382</td> <td>  282.480</td> <td>    4.677</td> <td> 0.000</td> <td>  767.165</td> <td> 1875.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -514.9809</td> <td>   64.277</td> <td>   -8.012</td> <td> 0.000</td> <td> -641.035</td> <td> -388.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> -618.9689</td> <td>  235.321</td> <td>   -2.630</td> <td> 0.009</td> <td>-1080.457</td> <td> -157.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>  -18.2142</td> <td>    1.008</td> <td>  -18.075</td> <td> 0.000</td> <td>  -20.190</td> <td>  -16.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>  -31.9166</td> <td>    8.003</td> <td>   -3.988</td> <td> 0.000</td> <td>  -47.610</td> <td>  -16.223</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>23.944</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.189</td> <th>  Prob(JB):          </th> <td>7.17e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.423</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.264\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     32.47\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          9.40e-121\n",
       "Time:                        17:55:29   Log-Likelihood:                -17397.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2086   BIC:                         3.498e+04\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6500.1412     74.106     87.714      0.000    6354.812    6645.470\n",
       "x1          -433.1803    175.054     -2.475      0.013    -776.479     -89.881\n",
       "x2         -1077.9300    122.189     -8.822      0.000   -1317.554    -838.306\n",
       "x3          -237.5470    137.179     -1.732      0.083    -506.569      31.475\n",
       "x4          -415.7589    107.251     -3.876      0.000    -626.090    -205.428\n",
       "x5         -1395.2945    465.483     -2.998      0.003   -2308.154    -482.435\n",
       "x6         -1681.8704    352.709     -4.768      0.000   -2373.569    -990.171\n",
       "x7          -362.1080    186.720     -1.939      0.053    -728.286       4.070\n",
       "x8          -305.3262     80.690     -3.784      0.000    -463.567    -147.085\n",
       "x9          -136.5869    131.569     -1.038      0.299    -394.607     121.433\n",
       "x10         -255.0621    312.189     -0.817      0.414    -867.297     357.173\n",
       "x11         1713.5438    148.707     11.523      0.000    1421.915    2005.173\n",
       "x12         -654.7178    540.047     -1.212      0.226   -1713.805     404.369\n",
       "x13        -1711.2653    311.697     -5.490      0.000   -2322.535   -1099.996\n",
       "x14         -168.6948    111.614     -1.511      0.131    -387.581      50.191\n",
       "x15        -1635.0762    656.722     -2.490      0.013   -2922.974    -347.178\n",
       "x16         -341.6249     73.957     -4.619      0.000    -486.663    -196.587\n",
       "x17         -131.1802     76.267     -1.720      0.086    -280.747      18.387\n",
       "x18         -643.9601     95.301     -6.757      0.000    -830.855    -457.065\n",
       "x19         1321.1382    282.480      4.677      0.000     767.165    1875.111\n",
       "x20         -514.9809     64.277     -8.012      0.000    -641.035    -388.926\n",
       "x21         -618.9689    235.321     -2.630      0.009   -1080.457    -157.481\n",
       "x22          -18.2142      1.008    -18.075      0.000     -20.190     -16.238\n",
       "x23          -31.9166      8.003     -3.988      0.000     -47.610     -16.223\n",
       "==============================================================================\n",
       "Omnibus:                       23.944   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.296\n",
       "Skew:                           0.189   Prob(JB):                     7.17e-07\n",
       "Kurtosis:                       3.423   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.263</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.256</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   33.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.20e-121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:55:58</td>     <th>  Log-Likelihood:    </th> <td> -17397.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2087</td>      <th>  BIC:               </th> <td>3.497e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    22</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6498.1717</td> <td>   74.061</td> <td>   87.741</td> <td> 0.000</td> <td> 6352.931</td> <td> 6643.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -429.4215</td> <td>  174.980</td> <td>   -2.454</td> <td> 0.014</td> <td> -772.574</td> <td>  -86.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1074.1480</td> <td>  122.091</td> <td>   -8.798</td> <td> 0.000</td> <td>-1313.581</td> <td> -834.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -233.5344</td> <td>  137.080</td> <td>   -1.704</td> <td> 0.089</td> <td> -502.362</td> <td>   35.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -412.0919</td> <td>  107.149</td> <td>   -3.846</td> <td> 0.000</td> <td> -622.222</td> <td> -201.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1390.1425</td> <td>  465.403</td> <td>   -2.987</td> <td> 0.003</td> <td>-2302.845</td> <td> -477.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1677.8099</td> <td>  352.646</td> <td>   -4.758</td> <td> 0.000</td> <td>-2369.385</td> <td> -986.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -358.3273</td> <td>  186.648</td> <td>   -1.920</td> <td> 0.055</td> <td> -724.363</td> <td>    7.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -301.1339</td> <td>   80.520</td> <td>   -3.740</td> <td> 0.000</td> <td> -459.042</td> <td> -143.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -132.7371</td> <td>  131.474</td> <td>   -1.010</td> <td> 0.313</td> <td> -390.571</td> <td>  125.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> 1717.5415</td> <td>  148.614</td> <td>   11.557</td> <td> 0.000</td> <td> 1426.094</td> <td> 2008.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> -647.3320</td> <td>  539.928</td> <td>   -1.199</td> <td> 0.231</td> <td>-1706.186</td> <td>  411.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>-1706.9371</td> <td>  311.627</td> <td>   -5.478</td> <td> 0.000</td> <td>-2318.069</td> <td>-1095.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -164.9574</td> <td>  111.511</td> <td>   -1.479</td> <td> 0.139</td> <td> -383.642</td> <td>   53.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>-1630.6426</td> <td>  656.647</td> <td>   -2.483</td> <td> 0.013</td> <td>-2918.393</td> <td> -342.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -337.5752</td> <td>   73.785</td> <td>   -4.575</td> <td> 0.000</td> <td> -482.276</td> <td> -192.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -127.5473</td> <td>   76.131</td> <td>   -1.675</td> <td> 0.094</td> <td> -276.848</td> <td>   21.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -640.0789</td> <td>   95.175</td> <td>   -6.725</td> <td> 0.000</td> <td> -826.726</td> <td> -453.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> 1325.0559</td> <td>  282.417</td> <td>    4.692</td> <td> 0.000</td> <td>  771.207</td> <td> 1878.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -510.8481</td> <td>   64.073</td> <td>   -7.973</td> <td> 0.000</td> <td> -636.502</td> <td> -385.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -615.0928</td> <td>  235.254</td> <td>   -2.615</td> <td> 0.009</td> <td>-1076.450</td> <td> -153.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>  -18.2622</td> <td>    1.006</td> <td>  -18.154</td> <td> 0.000</td> <td>  -20.235</td> <td>  -16.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>  -31.7612</td> <td>    8.000</td> <td>   -3.970</td> <td> 0.000</td> <td>  -47.449</td> <td>  -16.073</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.193</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.191</td> <th>  Prob(JB):          </th> <td>6.30e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.423</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.263\n",
       "Model:                            OLS   Adj. R-squared:                  0.256\n",
       "Method:                 Least Squares   F-statistic:                     33.92\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          2.20e-121\n",
       "Time:                        17:55:58   Log-Likelihood:                -17397.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2087   BIC:                         3.497e+04\n",
       "Df Model:                          22                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6498.1717     74.061     87.741      0.000    6352.931    6643.412\n",
       "x1          -429.4215    174.980     -2.454      0.014    -772.574     -86.268\n",
       "x2         -1074.1480    122.091     -8.798      0.000   -1313.581    -834.715\n",
       "x3          -233.5344    137.080     -1.704      0.089    -502.362      35.293\n",
       "x4          -412.0919    107.149     -3.846      0.000    -622.222    -201.962\n",
       "x5         -1390.1425    465.403     -2.987      0.003   -2302.845    -477.440\n",
       "x6         -1677.8099    352.646     -4.758      0.000   -2369.385    -986.235\n",
       "x7          -358.3273    186.648     -1.920      0.055    -724.363       7.709\n",
       "x8          -301.1339     80.520     -3.740      0.000    -459.042    -143.226\n",
       "x9          -132.7371    131.474     -1.010      0.313    -390.571     125.097\n",
       "x10         1717.5415    148.614     11.557      0.000    1426.094    2008.989\n",
       "x11         -647.3320    539.928     -1.199      0.231   -1706.186     411.522\n",
       "x12        -1706.9371    311.627     -5.478      0.000   -2318.069   -1095.805\n",
       "x13         -164.9574    111.511     -1.479      0.139    -383.642      53.727\n",
       "x14        -1630.6426    656.647     -2.483      0.013   -2918.393    -342.892\n",
       "x15         -337.5752     73.785     -4.575      0.000    -482.276    -192.875\n",
       "x16         -127.5473     76.131     -1.675      0.094    -276.848      21.753\n",
       "x17         -640.0789     95.175     -6.725      0.000    -826.726    -453.432\n",
       "x18         1325.0559    282.417      4.692      0.000     771.207    1878.905\n",
       "x19         -510.8481     64.073     -7.973      0.000    -636.502    -385.195\n",
       "x20         -615.0928    235.254     -2.615      0.009   -1076.450    -153.736\n",
       "x21          -18.2622      1.006    -18.154      0.000     -20.235     -16.289\n",
       "x22          -31.7612      8.000     -3.970      0.000     -47.449     -16.073\n",
       "==============================================================================\n",
       "Omnibus:                       24.193   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.556\n",
       "Skew:                           0.191   Prob(JB):                     6.30e-07\n",
       "Kurtosis:                       3.423   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x10, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,9,11,12,15,19,20,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.263</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.256</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   35.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>6.00e-122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:56:22</td>     <th>  Log-Likelihood:    </th> <td> -17398.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2088</td>      <th>  BIC:               </th> <td>3.496e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    21</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6481.8977</td> <td>   72.286</td> <td>   89.671</td> <td> 0.000</td> <td> 6340.139</td> <td> 6623.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -417.1971</td> <td>  174.561</td> <td>   -2.390</td> <td> 0.017</td> <td> -759.529</td> <td>  -74.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1061.2325</td> <td>  121.420</td> <td>   -8.740</td> <td> 0.000</td> <td>-1299.349</td> <td> -823.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -221.0377</td> <td>  136.521</td> <td>   -1.619</td> <td> 0.106</td> <td> -488.768</td> <td>   46.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -399.1324</td> <td>  106.378</td> <td>   -3.752</td> <td> 0.000</td> <td> -607.750</td> <td> -190.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1378.7472</td> <td>  465.269</td> <td>   -2.963</td> <td> 0.003</td> <td>-2291.186</td> <td> -466.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1665.0813</td> <td>  352.422</td> <td>   -4.725</td> <td> 0.000</td> <td>-2356.217</td> <td> -973.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -345.1793</td> <td>  186.194</td> <td>   -1.854</td> <td> 0.064</td> <td> -710.325</td> <td>   19.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -288.7251</td> <td>   79.577</td> <td>   -3.628</td> <td> 0.000</td> <td> -444.784</td> <td> -132.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 1729.9198</td> <td>  148.109</td> <td>   11.680</td> <td> 0.000</td> <td> 1439.464</td> <td> 2020.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -639.0357</td> <td>  539.868</td> <td>   -1.184</td> <td> 0.237</td> <td>-1697.772</td> <td>  419.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>-1694.4603</td> <td>  311.383</td> <td>   -5.442</td> <td> 0.000</td> <td>-2305.114</td> <td>-1083.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -152.2352</td> <td>  110.797</td> <td>   -1.374</td> <td> 0.170</td> <td> -369.520</td> <td>   65.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>-1618.1552</td> <td>  656.533</td> <td>   -2.465</td> <td> 0.014</td> <td>-2905.683</td> <td> -330.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -324.9646</td> <td>   72.721</td> <td>   -4.469</td> <td> 0.000</td> <td> -467.577</td> <td> -182.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -114.9113</td> <td>   75.095</td> <td>   -1.530</td> <td> 0.126</td> <td> -262.181</td> <td>   32.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -627.9990</td> <td>   94.420</td> <td>   -6.651</td> <td> 0.000</td> <td> -813.166</td> <td> -442.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 1337.4366</td> <td>  282.152</td> <td>    4.740</td> <td> 0.000</td> <td>  784.108</td> <td> 1890.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -498.3363</td> <td>   62.863</td> <td>   -7.927</td> <td> 0.000</td> <td> -621.617</td> <td> -375.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> -602.2646</td> <td>  234.912</td> <td>   -2.564</td> <td> 0.010</td> <td>-1062.950</td> <td> -141.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>  -18.1941</td> <td>    1.004</td> <td>  -18.127</td> <td> 0.000</td> <td>  -20.162</td> <td>  -16.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>  -31.6934</td> <td>    7.999</td> <td>   -3.962</td> <td> 0.000</td> <td>  -47.381</td> <td>  -16.006</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.277</td> <th>  Durbin-Watson:     </th> <td>   1.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.192</td> <th>  Prob(JB):          </th> <td>6.26e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.421</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.263\n",
       "Model:                            OLS   Adj. R-squared:                  0.256\n",
       "Method:                 Least Squares   F-statistic:                     35.48\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          6.00e-122\n",
       "Time:                        17:56:22   Log-Likelihood:                -17398.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2088   BIC:                         3.496e+04\n",
       "Df Model:                          21                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6481.8977     72.286     89.671      0.000    6340.139    6623.657\n",
       "x1          -417.1971    174.561     -2.390      0.017    -759.529     -74.865\n",
       "x2         -1061.2325    121.420     -8.740      0.000   -1299.349    -823.116\n",
       "x3          -221.0377    136.521     -1.619      0.106    -488.768      46.693\n",
       "x4          -399.1324    106.378     -3.752      0.000    -607.750    -190.515\n",
       "x5         -1378.7472    465.269     -2.963      0.003   -2291.186    -466.309\n",
       "x6         -1665.0813    352.422     -4.725      0.000   -2356.217    -973.945\n",
       "x7          -345.1793    186.194     -1.854      0.064    -710.325      19.966\n",
       "x8          -288.7251     79.577     -3.628      0.000    -444.784    -132.667\n",
       "x9          1729.9198    148.109     11.680      0.000    1439.464    2020.375\n",
       "x10         -639.0357    539.868     -1.184      0.237   -1697.772     419.700\n",
       "x11        -1694.4603    311.383     -5.442      0.000   -2305.114   -1083.806\n",
       "x12         -152.2352    110.797     -1.374      0.170    -369.520      65.050\n",
       "x13        -1618.1552    656.533     -2.465      0.014   -2905.683    -330.627\n",
       "x14         -324.9646     72.721     -4.469      0.000    -467.577    -182.352\n",
       "x15         -114.9113     75.095     -1.530      0.126    -262.181      32.358\n",
       "x16         -627.9990     94.420     -6.651      0.000    -813.166    -442.832\n",
       "x17         1337.4366    282.152      4.740      0.000     784.108    1890.765\n",
       "x18         -498.3363     62.863     -7.927      0.000    -621.617    -375.055\n",
       "x19         -602.2646    234.912     -2.564      0.010   -1062.950    -141.579\n",
       "x20          -18.1941      1.004    -18.127      0.000     -20.162     -16.226\n",
       "x21          -31.6934      7.999     -3.962      0.000     -47.381     -16.006\n",
       "==============================================================================\n",
       "Omnibus:                       24.277   Durbin-Watson:                   1.952\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.568\n",
       "Skew:                           0.192   Prob(JB):                     6.26e-07\n",
       "Kurtosis:                       3.421   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x9, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,11,12,15,19,20,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.263</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.18</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>1.92e-122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:56:52</td>     <th>  Log-Likelihood:    </th> <td> -17398.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2089</td>      <th>  BIC:               </th> <td>3.496e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6485.5876</td> <td>   72.225</td> <td>   89.797</td> <td> 0.000</td> <td> 6343.947</td> <td> 6627.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -414.6513</td> <td>  174.565</td> <td>   -2.375</td> <td> 0.018</td> <td> -756.990</td> <td>  -72.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1059.2656</td> <td>  121.420</td> <td>   -8.724</td> <td> 0.000</td> <td>-1297.382</td> <td> -821.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -218.3588</td> <td>  136.515</td> <td>   -1.600</td> <td> 0.110</td> <td> -486.078</td> <td>   49.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -397.3744</td> <td>  106.378</td> <td>   -3.736</td> <td> 0.000</td> <td> -605.991</td> <td> -188.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1373.4078</td> <td>  465.291</td> <td>   -2.952</td> <td> 0.003</td> <td>-2285.891</td> <td> -460.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1662.5372</td> <td>  352.450</td> <td>   -4.717</td> <td> 0.000</td> <td>-2353.726</td> <td> -971.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -343.4206</td> <td>  186.206</td> <td>   -1.844</td> <td> 0.065</td> <td> -708.590</td> <td>   21.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -285.7025</td> <td>   79.544</td> <td>   -3.592</td> <td> 0.000</td> <td> -441.696</td> <td> -129.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 1732.6820</td> <td>  148.104</td> <td>   11.699</td> <td> 0.000</td> <td> 1442.235</td> <td> 2023.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-1691.2973</td> <td>  311.402</td> <td>   -5.431</td> <td> 0.000</td> <td>-2301.987</td> <td>-1080.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> -150.1626</td> <td>  110.794</td> <td>   -1.355</td> <td> 0.175</td> <td> -367.441</td> <td>   67.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>-1614.8461</td> <td>  656.590</td> <td>   -2.459</td> <td> 0.014</td> <td>-2902.486</td> <td> -327.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -322.3317</td> <td>   72.694</td> <td>   -4.434</td> <td> 0.000</td> <td> -464.891</td> <td> -179.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -112.9166</td> <td>   75.084</td> <td>   -1.504</td> <td> 0.133</td> <td> -260.163</td> <td>   34.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -625.1444</td> <td>   94.398</td> <td>   -6.622</td> <td> 0.000</td> <td> -810.269</td> <td> -440.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 1340.0783</td> <td>  282.170</td> <td>    4.749</td> <td> 0.000</td> <td>  786.714</td> <td> 1893.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -495.4930</td> <td>   62.823</td> <td>   -7.887</td> <td> 0.000</td> <td> -618.696</td> <td> -372.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> -600.0812</td> <td>  234.927</td> <td>   -2.554</td> <td> 0.011</td> <td>-1060.797</td> <td> -139.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>  -18.3254</td> <td>    0.998</td> <td>  -18.369</td> <td> 0.000</td> <td>  -20.282</td> <td>  -16.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>  -31.5241</td> <td>    7.999</td> <td>   -3.941</td> <td> 0.000</td> <td>  -47.211</td> <td>  -15.837</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.553</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.193</td> <th>  Prob(JB):          </th> <td>5.18e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.424</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.263\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     37.18\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          1.92e-122\n",
       "Time:                        17:56:52   Log-Likelihood:                -17398.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2089   BIC:                         3.496e+04\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6485.5876     72.225     89.797      0.000    6343.947    6627.228\n",
       "x1          -414.6513    174.565     -2.375      0.018    -756.990     -72.313\n",
       "x2         -1059.2656    121.420     -8.724      0.000   -1297.382    -821.149\n",
       "x3          -218.3588    136.515     -1.600      0.110    -486.078      49.361\n",
       "x4          -397.3744    106.378     -3.736      0.000    -605.991    -188.757\n",
       "x5         -1373.4078    465.291     -2.952      0.003   -2285.891    -460.925\n",
       "x6         -1662.5372    352.450     -4.717      0.000   -2353.726    -971.348\n",
       "x7          -343.4206    186.206     -1.844      0.065    -708.590      21.748\n",
       "x8          -285.7025     79.544     -3.592      0.000    -441.696    -129.709\n",
       "x9          1732.6820    148.104     11.699      0.000    1442.235    2023.129\n",
       "x10        -1691.2973    311.402     -5.431      0.000   -2301.987   -1080.607\n",
       "x11         -150.1626    110.794     -1.355      0.175    -367.441      67.116\n",
       "x12        -1614.8461    656.590     -2.459      0.014   -2902.486    -327.207\n",
       "x13         -322.3317     72.694     -4.434      0.000    -464.891    -179.772\n",
       "x14         -112.9166     75.084     -1.504      0.133    -260.163      34.330\n",
       "x15         -625.1444     94.398     -6.622      0.000    -810.269    -440.020\n",
       "x16         1340.0783    282.170      4.749      0.000     786.714    1893.443\n",
       "x17         -495.4930     62.823     -7.887      0.000    -618.696    -372.290\n",
       "x18         -600.0812    234.927     -2.554      0.011   -1060.797    -139.366\n",
       "x19          -18.3254      0.998    -18.369      0.000     -20.282     -16.369\n",
       "x20          -31.5241      7.999     -3.941      0.000     -47.211     -15.837\n",
       "==============================================================================\n",
       "Omnibus:                       24.553   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.947\n",
       "Skew:                           0.193   Prob(JB):                     5.18e-07\n",
       "Kurtosis:                       3.424   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x10, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,11,15,19,20,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.262</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>7.41e-123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:21</td>     <th>  Log-Likelihood:    </th> <td> -17399.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2090</td>      <th>  BIC:               </th> <td>3.495e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6464.9556</td> <td>   70.617</td> <td>   91.550</td> <td> 0.000</td> <td> 6326.469</td> <td> 6603.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -395.2715</td> <td>  174.013</td> <td>   -2.272</td> <td> 0.023</td> <td> -736.528</td> <td>  -54.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1040.8542</td> <td>  120.682</td> <td>   -8.625</td> <td> 0.000</td> <td>-1277.523</td> <td> -804.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -200.2407</td> <td>  135.886</td> <td>   -1.474</td> <td> 0.141</td> <td> -466.727</td> <td>   66.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -378.6056</td> <td>  105.493</td> <td>   -3.589</td> <td> 0.000</td> <td> -585.489</td> <td> -171.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1357.9794</td> <td>  465.245</td> <td>   -2.919</td> <td> 0.004</td> <td>-2270.372</td> <td> -445.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1644.8887</td> <td>  352.280</td> <td>   -4.669</td> <td> 0.000</td> <td>-2335.744</td> <td> -954.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -325.3024</td> <td>  185.763</td> <td>   -1.751</td> <td> 0.080</td> <td> -689.602</td> <td>   38.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -268.1187</td> <td>   78.494</td> <td>   -3.416</td> <td> 0.001</td> <td> -422.054</td> <td> -114.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 1751.0051</td> <td>  147.516</td> <td>   11.870</td> <td> 0.000</td> <td> 1461.712</td> <td> 2040.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-1674.2895</td> <td>  311.211</td> <td>   -5.380</td> <td> 0.000</td> <td>-2284.605</td> <td>-1063.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>-1598.2310</td> <td>  656.607</td> <td>   -2.434</td> <td> 0.015</td> <td>-2885.903</td> <td> -310.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -304.4933</td> <td>   71.507</td> <td>   -4.258</td> <td> 0.000</td> <td> -444.725</td> <td> -164.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>  -93.6109</td> <td>   73.735</td> <td>   -1.270</td> <td> 0.204</td> <td> -238.213</td> <td>   50.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -606.0197</td> <td>   93.356</td> <td>   -6.491</td> <td> 0.000</td> <td> -789.101</td> <td> -422.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> 1358.6862</td> <td>  281.893</td> <td>    4.820</td> <td> 0.000</td> <td>  805.867</td> <td> 1911.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -477.8271</td> <td>   61.469</td> <td>   -7.774</td> <td> 0.000</td> <td> -598.373</td> <td> -357.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> -581.8967</td> <td>  234.591</td> <td>   -2.480</td> <td> 0.013</td> <td>-1041.952</td> <td> -121.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  -18.2400</td> <td>    0.996</td> <td>  -18.316</td> <td> 0.000</td> <td>  -20.193</td> <td>  -16.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>  -32.1700</td> <td>    7.986</td> <td>   -4.028</td> <td> 0.000</td> <td>  -47.832</td> <td>  -16.508</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>23.360</td> <th>  Durbin-Watson:     </th> <td>   1.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  27.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.186</td> <th>  Prob(JB):          </th> <td>1.05e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.417</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.262\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     39.02\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          7.41e-123\n",
       "Time:                        18:03:21   Log-Likelihood:                -17399.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2090   BIC:                         3.495e+04\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6464.9556     70.617     91.550      0.000    6326.469    6603.442\n",
       "x1          -395.2715    174.013     -2.272      0.023    -736.528     -54.015\n",
       "x2         -1040.8542    120.682     -8.625      0.000   -1277.523    -804.185\n",
       "x3          -200.2407    135.886     -1.474      0.141    -466.727      66.245\n",
       "x4          -378.6056    105.493     -3.589      0.000    -585.489    -171.723\n",
       "x5         -1357.9794    465.245     -2.919      0.004   -2270.372    -445.587\n",
       "x6         -1644.8887    352.280     -4.669      0.000   -2335.744    -954.033\n",
       "x7          -325.3024    185.763     -1.751      0.080    -689.602      38.997\n",
       "x8          -268.1187     78.494     -3.416      0.001    -422.054    -114.184\n",
       "x9          1751.0051    147.516     11.870      0.000    1461.712    2040.298\n",
       "x10        -1674.2895    311.211     -5.380      0.000   -2284.605   -1063.974\n",
       "x11        -1598.2310    656.607     -2.434      0.015   -2885.903    -310.559\n",
       "x12         -304.4933     71.507     -4.258      0.000    -444.725    -164.262\n",
       "x13          -93.6109     73.735     -1.270      0.204    -238.213      50.991\n",
       "x14         -606.0197     93.356     -6.491      0.000    -789.101    -422.938\n",
       "x15         1358.6862    281.893      4.820      0.000     805.867    1911.506\n",
       "x16         -477.8271     61.469     -7.774      0.000    -598.373    -357.281\n",
       "x17         -581.8967    234.591     -2.480      0.013   -1041.952    -121.841\n",
       "x18          -18.2400      0.996    -18.316      0.000     -20.193     -16.287\n",
       "x19          -32.1700      7.986     -4.028      0.000     -47.832     -16.508\n",
       "==============================================================================\n",
       "Omnibus:                       23.360   Durbin-Watson:                   1.949\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               27.530\n",
       "Skew:                           0.186   Prob(JB):                     1.05e-06\n",
       "Kurtosis:                       3.417   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x11, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,11,15,20,23,24,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.261</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.09</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.50e-123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:56</td>     <th>  Log-Likelihood:    </th> <td> -17400.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2091</td>      <th>  BIC:               </th> <td>3.495e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6442.9751</td> <td>   68.472</td> <td>   94.097</td> <td> 0.000</td> <td> 6308.696</td> <td> 6577.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -369.2564</td> <td>  172.827</td> <td>   -2.137</td> <td> 0.033</td> <td> -708.188</td> <td>  -30.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1018.4097</td> <td>  119.397</td> <td>   -8.530</td> <td> 0.000</td> <td>-1252.560</td> <td> -784.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -177.7785</td> <td>  134.749</td> <td>   -1.319</td> <td> 0.187</td> <td> -442.035</td> <td>   86.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -355.3670</td> <td>  103.908</td> <td>   -3.420</td> <td> 0.001</td> <td> -559.142</td> <td> -151.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1340.1468</td> <td>  465.101</td> <td>   -2.881</td> <td> 0.004</td> <td>-2252.256</td> <td> -428.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1623.9769</td> <td>  351.946</td> <td>   -4.614</td> <td> 0.000</td> <td>-2314.178</td> <td> -933.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -303.9797</td> <td>  185.029</td> <td>   -1.643</td> <td> 0.101</td> <td> -666.840</td> <td>   58.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> -246.8048</td> <td>   76.689</td> <td>   -3.218</td> <td> 0.001</td> <td> -397.200</td> <td>  -96.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 1774.1746</td> <td>  146.404</td> <td>   12.118</td> <td> 0.000</td> <td> 1487.062</td> <td> 2061.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-1654.4990</td> <td>  310.866</td> <td>   -5.322</td> <td> 0.000</td> <td>-2264.138</td> <td>-1044.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>-1579.4166</td> <td>  656.536</td> <td>   -2.406</td> <td> 0.016</td> <td>-2866.949</td> <td> -291.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -282.9120</td> <td>   69.467</td> <td>   -4.073</td> <td> 0.000</td> <td> -419.143</td> <td> -146.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -580.3735</td> <td>   91.158</td> <td>   -6.367</td> <td> 0.000</td> <td> -759.143</td> <td> -401.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> 1382.5457</td> <td>  281.307</td> <td>    4.915</td> <td> 0.000</td> <td>  830.876</td> <td> 1934.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -456.4936</td> <td>   59.136</td> <td>   -7.719</td> <td> 0.000</td> <td> -572.465</td> <td> -340.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> -559.8524</td> <td>  233.981</td> <td>   -2.393</td> <td> 0.017</td> <td>-1018.713</td> <td> -100.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>  -18.1510</td> <td>    0.994</td> <td>  -18.270</td> <td> 0.000</td> <td>  -20.099</td> <td>  -16.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  -33.8635</td> <td>    7.875</td> <td>   -4.300</td> <td> 0.000</td> <td>  -49.308</td> <td>  -18.419</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>22.488</td> <th>  Durbin-Watson:     </th> <td>   1.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  26.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.184</td> <th>  Prob(JB):          </th> <td>1.99e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.403</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.261\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     41.09\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          2.50e-123\n",
       "Time:                        18:03:56   Log-Likelihood:                -17400.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2091   BIC:                         3.495e+04\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6442.9751     68.472     94.097      0.000    6308.696    6577.255\n",
       "x1          -369.2564    172.827     -2.137      0.033    -708.188     -30.325\n",
       "x2         -1018.4097    119.397     -8.530      0.000   -1252.560    -784.260\n",
       "x3          -177.7785    134.749     -1.319      0.187    -442.035      86.478\n",
       "x4          -355.3670    103.908     -3.420      0.001    -559.142    -151.592\n",
       "x5         -1340.1468    465.101     -2.881      0.004   -2252.256    -428.037\n",
       "x6         -1623.9769    351.946     -4.614      0.000   -2314.178    -933.776\n",
       "x7          -303.9797    185.029     -1.643      0.101    -666.840      58.881\n",
       "x8          -246.8048     76.689     -3.218      0.001    -397.200     -96.410\n",
       "x9          1774.1746    146.404     12.118      0.000    1487.062    2061.287\n",
       "x10        -1654.4990    310.866     -5.322      0.000   -2264.138   -1044.860\n",
       "x11        -1579.4166    656.536     -2.406      0.016   -2866.949    -291.884\n",
       "x12         -282.9120     69.467     -4.073      0.000    -419.143    -146.681\n",
       "x13         -580.3735     91.158     -6.367      0.000    -759.143    -401.604\n",
       "x14         1382.5457    281.307      4.915      0.000     830.876    1934.216\n",
       "x15         -456.4936     59.136     -7.719      0.000    -572.465    -340.522\n",
       "x16         -559.8524    233.981     -2.393      0.017   -1018.713    -100.992\n",
       "x17          -18.1510      0.994    -18.270      0.000     -20.099     -16.203\n",
       "x18          -33.8635      7.875     -4.300      0.000     -49.308     -18.419\n",
       "==============================================================================\n",
       "Omnibus:                       22.488   Durbin-Watson:                   1.948\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.254\n",
       "Skew:                           0.184   Prob(JB):                     1.99e-06\n",
       "Kurtosis:                       3.403   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x13, so I remove it\n",
    "X_opt=X[:, [0,1,2,3,4,5,6,7,8,11,15,20,23,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.261</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   43.39</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>8.76e-124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:04:24</td>     <th>  Log-Likelihood:    </th> <td> -17401.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2092</td>      <th>  BIC:               </th> <td>3.494e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6432.4697</td> <td>   68.019</td> <td>   94.569</td> <td> 0.000</td> <td> 6299.078</td> <td> 6565.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -360.0688</td> <td>  172.718</td> <td>   -2.085</td> <td> 0.037</td> <td> -698.785</td> <td>  -21.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1008.8352</td> <td>  119.198</td> <td>   -8.464</td> <td> 0.000</td> <td>-1242.594</td> <td> -775.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -345.8253</td> <td>  103.675</td> <td>   -3.336</td> <td> 0.001</td> <td> -549.142</td> <td> -142.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-1330.7226</td> <td>  465.129</td> <td>   -2.861</td> <td> 0.004</td> <td>-2242.886</td> <td> -418.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1614.3666</td> <td>  351.933</td> <td>   -4.587</td> <td> 0.000</td> <td>-2304.541</td> <td> -924.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> -294.2795</td> <td>  184.916</td> <td>   -1.591</td> <td> 0.112</td> <td> -656.917</td> <td>   68.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> -237.3033</td> <td>   76.364</td> <td>   -3.108</td> <td> 0.002</td> <td> -387.060</td> <td>  -87.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 1783.5636</td> <td>  146.257</td> <td>   12.195</td> <td> 0.000</td> <td> 1496.740</td> <td> 2070.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-1644.8936</td> <td>  310.836</td> <td>   -5.292</td> <td> 0.000</td> <td>-2254.473</td> <td>-1035.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-1569.7534</td> <td>  656.611</td> <td>   -2.391</td> <td> 0.017</td> <td>-2857.433</td> <td> -282.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> -273.3712</td> <td>   69.102</td> <td>   -3.956</td> <td> 0.000</td> <td> -408.886</td> <td> -137.856</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> -571.2041</td> <td>   90.909</td> <td>   -6.283</td> <td> 0.000</td> <td> -749.485</td> <td> -392.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 1391.8966</td> <td>  281.267</td> <td>    4.949</td> <td> 0.000</td> <td>  840.304</td> <td> 1943.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -446.9654</td> <td>   58.704</td> <td>   -7.614</td> <td> 0.000</td> <td> -562.089</td> <td> -331.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -550.2790</td> <td>  233.910</td> <td>   -2.353</td> <td> 0.019</td> <td>-1009.000</td> <td>  -91.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>  -18.1376</td> <td>    0.994</td> <td>  -18.254</td> <td> 0.000</td> <td>  -20.086</td> <td>  -16.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>  -33.7500</td> <td>    7.876</td> <td>   -4.285</td> <td> 0.000</td> <td>  -49.196</td> <td>  -18.304</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>21.334</td> <th>  Durbin-Watson:     </th> <td>   1.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.181</td> <th>  Prob(JB):          </th> <td>4.46e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.386</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.261\n",
       "Model:                            OLS   Adj. R-squared:                  0.255\n",
       "Method:                 Least Squares   F-statistic:                     43.39\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          8.76e-124\n",
       "Time:                        18:04:24   Log-Likelihood:                -17401.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2092   BIC:                         3.494e+04\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6432.4697     68.019     94.569      0.000    6299.078    6565.862\n",
       "x1          -360.0688    172.718     -2.085      0.037    -698.785     -21.353\n",
       "x2         -1008.8352    119.198     -8.464      0.000   -1242.594    -775.077\n",
       "x3          -345.8253    103.675     -3.336      0.001    -549.142    -142.509\n",
       "x4         -1330.7226    465.129     -2.861      0.004   -2242.886    -418.560\n",
       "x5         -1614.3666    351.933     -4.587      0.000   -2304.541    -924.192\n",
       "x6          -294.2795    184.916     -1.591      0.112    -656.917      68.359\n",
       "x7          -237.3033     76.364     -3.108      0.002    -387.060     -87.547\n",
       "x8          1783.5636    146.257     12.195      0.000    1496.740    2070.387\n",
       "x9         -1644.8936    310.836     -5.292      0.000   -2254.473   -1035.314\n",
       "x10        -1569.7534    656.611     -2.391      0.017   -2857.433    -282.074\n",
       "x11         -273.3712     69.102     -3.956      0.000    -408.886    -137.856\n",
       "x12         -571.2041     90.909     -6.283      0.000    -749.485    -392.923\n",
       "x13         1391.8966    281.267      4.949      0.000     840.304    1943.489\n",
       "x14         -446.9654     58.704     -7.614      0.000    -562.089    -331.842\n",
       "x15         -550.2790    233.910     -2.353      0.019   -1009.000     -91.558\n",
       "x16          -18.1376      0.994    -18.254      0.000     -20.086     -16.189\n",
       "x17          -33.7500      7.876     -4.285      0.000     -49.196     -18.304\n",
       "==============================================================================\n",
       "Omnibus:                       21.334   Durbin-Watson:                   1.946\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.640\n",
       "Skew:                           0.181   Prob(JB):                     4.46e-06\n",
       "Kurtosis:                       3.386   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x3, so I remove it\n",
    "X_opt=X[:, [0,1,2,4,5,6,7,8,11,15,20,23,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Cena_z/m2</td>    <th>  R-squared:         </th> <td>   0.260</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.254</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   45.91</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 28 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>4.39e-124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:04:52</td>     <th>  Log-Likelihood:    </th> <td> -17402.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2110</td>      <th>  AIC:               </th> <td>3.484e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2093</td>      <th>  BIC:               </th> <td>3.493e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    16</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 6417.4437</td> <td>   67.385</td> <td>   95.235</td> <td> 0.000</td> <td> 6285.295</td> <td> 6549.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -353.7816</td> <td>  172.736</td> <td>   -2.048</td> <td> 0.041</td> <td> -692.533</td> <td>  -15.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1000.0024</td> <td>  119.112</td> <td>   -8.395</td> <td> 0.000</td> <td>-1233.593</td> <td> -766.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> -337.2039</td> <td>  103.571</td> <td>   -3.256</td> <td> 0.001</td> <td> -540.317</td> <td> -134.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-1322.9293</td> <td>  465.273</td> <td>   -2.843</td> <td> 0.005</td> <td>-2235.375</td> <td> -410.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1605.3082</td> <td>  352.015</td> <td>   -4.560</td> <td> 0.000</td> <td>-2295.645</td> <td> -914.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> -228.9657</td> <td>   76.212</td> <td>   -3.004</td> <td> 0.003</td> <td> -378.424</td> <td>  -79.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 1791.1678</td> <td>  146.232</td> <td>   12.249</td> <td> 0.000</td> <td> 1504.393</td> <td> 2077.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>-1635.8767</td> <td>  310.898</td> <td>   -5.262</td> <td> 0.000</td> <td>-2245.578</td> <td>-1026.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-1560.3603</td> <td>  656.825</td> <td>   -2.376</td> <td> 0.018</td> <td>-2848.459</td> <td> -272.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> -264.7693</td> <td>   68.915</td> <td>   -3.842</td> <td> 0.000</td> <td> -399.919</td> <td> -129.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> -565.0409</td> <td>   90.859</td> <td>   -6.219</td> <td> 0.000</td> <td> -743.225</td> <td> -386.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 1399.2530</td> <td>  281.332</td> <td>    4.974</td> <td> 0.000</td> <td>  847.533</td> <td> 1950.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> -438.4500</td> <td>   58.481</td> <td>   -7.497</td> <td> 0.000</td> <td> -553.136</td> <td> -323.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> -541.4563</td> <td>  233.930</td> <td>   -2.315</td> <td> 0.021</td> <td>-1000.216</td> <td>  -82.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>  -18.0481</td> <td>    0.992</td> <td>  -18.186</td> <td> 0.000</td> <td>  -19.994</td> <td>  -16.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>  -33.0088</td> <td>    7.865</td> <td>   -4.197</td> <td> 0.000</td> <td>  -48.433</td> <td>  -17.584</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>20.572</td> <th>  Durbin-Watson:     </th> <td>   1.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.171</td> <th>  Prob(JB):          </th> <td>5.80e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.397</td> <th>  Cond. No.          </th> <td>1.85e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.85e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Cena_z/m2   R-squared:                       0.260\n",
       "Model:                            OLS   Adj. R-squared:                  0.254\n",
       "Method:                 Least Squares   F-statistic:                     45.91\n",
       "Date:                Wed, 28 Aug 2019   Prob (F-statistic):          4.39e-124\n",
       "Time:                        18:04:52   Log-Likelihood:                -17402.\n",
       "No. Observations:                2110   AIC:                         3.484e+04\n",
       "Df Residuals:                    2093   BIC:                         3.493e+04\n",
       "Df Model:                          16                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       6417.4437     67.385     95.235      0.000    6285.295    6549.593\n",
       "x1          -353.7816    172.736     -2.048      0.041    -692.533     -15.030\n",
       "x2         -1000.0024    119.112     -8.395      0.000   -1233.593    -766.412\n",
       "x3          -337.2039    103.571     -3.256      0.001    -540.317    -134.091\n",
       "x4         -1322.9293    465.273     -2.843      0.005   -2235.375    -410.483\n",
       "x5         -1605.3082    352.015     -4.560      0.000   -2295.645    -914.971\n",
       "x6          -228.9657     76.212     -3.004      0.003    -378.424     -79.507\n",
       "x7          1791.1678    146.232     12.249      0.000    1504.393    2077.943\n",
       "x8         -1635.8767    310.898     -5.262      0.000   -2245.578   -1026.176\n",
       "x9         -1560.3603    656.825     -2.376      0.018   -2848.459    -272.262\n",
       "x10         -264.7693     68.915     -3.842      0.000    -399.919    -129.620\n",
       "x11         -565.0409     90.859     -6.219      0.000    -743.225    -386.857\n",
       "x12         1399.2530    281.332      4.974      0.000     847.533    1950.973\n",
       "x13         -438.4500     58.481     -7.497      0.000    -553.136    -323.764\n",
       "x14         -541.4563    233.930     -2.315      0.021   -1000.216     -82.696\n",
       "x15          -18.0481      0.992    -18.186      0.000     -19.994     -16.102\n",
       "x16          -33.0088      7.865     -4.197      0.000     -48.433     -17.584\n",
       "==============================================================================\n",
       "Omnibus:                       20.572   Durbin-Watson:                   1.944\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.115\n",
       "Skew:                           0.171   Prob(JB):                     5.80e-06\n",
       "Kurtosis:                       3.397   Cond. No.                     1.85e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.85e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the highest P-value has x6, so I remove it\n",
    "X_opt=X[:, [0,1,2,4,5,6,8,11,15,20,23,25,26,27,28,29,30]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_opt, y,random_state=0 )\n",
    "\n",
    "# fitting Multiple Linear Regression to te training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train) # fitting the object to the training set\n",
    "# priedicting prices after Backward Elimination\n",
    "y_pred_withBE=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting prices without Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting prices without Backward Elimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y,random_state=0 )\n",
    "\n",
    "# fitting Multiple Linear Regression to te training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train) # fitting the object to the training set\n",
    "y_pred_without_BE=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting prices with automatic Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atomatic Backward Elimination ()\n",
    "import statsmodels.formula.api as sm\n",
    "def backwardElimination(x, sl):\n",
    "    \"\"\"\n",
    "    authors: Kirill Eremenko, Hadelin de Ponteves\n",
    "    \"\"\"\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = float(max(regressor_OLS.pvalues))\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL = 0.05\n",
    "X_opt = X[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29,30]] \n",
    "X_Modeled = backwardElimination(X_opt, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting prices after automatic Bacward Elimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_Modeled, y,random_state=0 )\n",
    "\n",
    "# fitting Multiple Linear Regression to te training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train) # fitting the object to the training set\n",
    "y_pred_automatic=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of results obtained in exercise no 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prices obtained with manual Backward Elimination\n",
    "prices_BE=pd.Series(y_pred_withBE, name='Prices with manual BE')\n",
    "# prices obtained with automatic Backward Elimination\n",
    "prices_automatic_BE=pd.Series(y_pred_automatic, name='Prices with automatic BE')\n",
    "# prices obtained without Backward Elimination\n",
    "prices_without_BE=pd.Series(y_pred_without_BE, name='Prices without BE' )\n",
    "\n",
    "real_prices=y_test.reset_index(drop=True).rename('Real prices')\n",
    "\n",
    "real_vs_predicted_BE=abs(round(100-prices_automatic_BE*100/real_prices,2)).rename('real vs predicted BE %')\n",
    "real_vs_predicted_without_BE=abs(round(100-prices_without_BE*100/real_prices,2)).rename('real vs predicted wthout BE %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real prices</th>\n",
       "      <th>Prices with manual BE</th>\n",
       "      <th>Prices with automatic BE</th>\n",
       "      <th>real vs predicted BE %</th>\n",
       "      <th>Prices without BE</th>\n",
       "      <th>real vs predicted wthout BE %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4635.92</td>\n",
       "      <td>5626.395377</td>\n",
       "      <td>5626.395377</td>\n",
       "      <td>21.37</td>\n",
       "      <td>5651.873428</td>\n",
       "      <td>21.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6391.75</td>\n",
       "      <td>5118.471951</td>\n",
       "      <td>5118.471951</td>\n",
       "      <td>19.92</td>\n",
       "      <td>5116.165915</td>\n",
       "      <td>19.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5987.39</td>\n",
       "      <td>5591.190356</td>\n",
       "      <td>5591.190356</td>\n",
       "      <td>6.62</td>\n",
       "      <td>5612.479775</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6727.02</td>\n",
       "      <td>5147.758036</td>\n",
       "      <td>5147.758036</td>\n",
       "      <td>23.48</td>\n",
       "      <td>5155.229561</td>\n",
       "      <td>23.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5668.02</td>\n",
       "      <td>5349.933641</td>\n",
       "      <td>5349.933641</td>\n",
       "      <td>5.61</td>\n",
       "      <td>5351.797586</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Real prices  Prices with manual BE  Prices with automatic BE  \\\n",
       "0      4635.92            5626.395377               5626.395377   \n",
       "1      6391.75            5118.471951               5118.471951   \n",
       "2      5987.39            5591.190356               5591.190356   \n",
       "3      6727.02            5147.758036               5147.758036   \n",
       "4      5668.02            5349.933641               5349.933641   \n",
       "\n",
       "   real vs predicted BE %  Prices without BE  real vs predicted wthout BE %  \n",
       "0                   21.37        5651.873428                          21.91  \n",
       "1                   19.92        5116.165915                          19.96  \n",
       "2                    6.62        5612.479775                           6.26  \n",
       "3                   23.48        5155.229561                          23.37  \n",
       "4                    5.61        5351.797586                           5.58  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison=pd.concat([real_prices, prices_BE, prices_automatic_BE, real_vs_predicted_BE, prices_without_BE, \n",
    "                      real_vs_predicted_without_BE], axis=1 )\n",
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real prices</th>\n",
       "      <th>Prices with manual BE</th>\n",
       "      <th>Prices with automatic BE</th>\n",
       "      <th>real vs predicted BE %</th>\n",
       "      <th>Prices without BE</th>\n",
       "      <th>real vs predicted wthout BE %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>528.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5187.843693</td>\n",
       "      <td>5231.564171</td>\n",
       "      <td>5231.564171</td>\n",
       "      <td>14.796307</td>\n",
       "      <td>5224.229427</td>\n",
       "      <td>14.718807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1054.082133</td>\n",
       "      <td>556.361856</td>\n",
       "      <td>556.361856</td>\n",
       "      <td>14.363853</td>\n",
       "      <td>556.399515</td>\n",
       "      <td>14.210853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2328.820000</td>\n",
       "      <td>3480.062942</td>\n",
       "      <td>3480.062942</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>3455.701693</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4502.865000</td>\n",
       "      <td>4962.886126</td>\n",
       "      <td>4962.886126</td>\n",
       "      <td>5.655000</td>\n",
       "      <td>4962.385823</td>\n",
       "      <td>5.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5082.915000</td>\n",
       "      <td>5258.067233</td>\n",
       "      <td>5258.067233</td>\n",
       "      <td>11.350000</td>\n",
       "      <td>5252.505315</td>\n",
       "      <td>11.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5931.670000</td>\n",
       "      <td>5476.587261</td>\n",
       "      <td>5476.587261</td>\n",
       "      <td>19.027500</td>\n",
       "      <td>5480.453778</td>\n",
       "      <td>19.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7950.100000</td>\n",
       "      <td>7588.140968</td>\n",
       "      <td>7588.140968</td>\n",
       "      <td>113.690000</td>\n",
       "      <td>7591.222942</td>\n",
       "      <td>113.650000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Real prices  Prices with manual BE  Prices with automatic BE  \\\n",
       "count   528.000000             528.000000                528.000000   \n",
       "mean   5187.843693            5231.564171               5231.564171   \n",
       "std    1054.082133             556.361856                556.361856   \n",
       "min    2328.820000            3480.062942               3480.062942   \n",
       "25%    4502.865000            4962.886126               4962.886126   \n",
       "50%    5082.915000            5258.067233               5258.067233   \n",
       "75%    5931.670000            5476.587261               5476.587261   \n",
       "max    7950.100000            7588.140968               7588.140968   \n",
       "\n",
       "       real vs predicted BE %  Prices without BE  \\\n",
       "count              528.000000         528.000000   \n",
       "mean                14.796307        5224.229427   \n",
       "std                 14.363853         556.399515   \n",
       "min                  0.110000        3455.701693   \n",
       "25%                  5.655000        4962.385823   \n",
       "50%                 11.350000        5252.505315   \n",
       "75%                 19.027500        5480.453778   \n",
       "max                113.690000        7591.222942   \n",
       "\n",
       "       real vs predicted wthout BE %  \n",
       "count                     528.000000  \n",
       "mean                       14.718807  \n",
       "std                        14.210853  \n",
       "min                         0.000000  \n",
       "25%                         5.502500  \n",
       "50%                        11.460000  \n",
       "75%                        19.385000  \n",
       "max                       113.650000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716.4436245630394\n",
      "714.578347209371\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(mean_absolute_error(y_test, y_pred_withBE))\n",
    "print(mean_absolute_error(y_test, y_pred_without_BE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results show that some of predicted prices are quite accurate but some of them are far away from real prices.\n",
    "# It means that model needs to be improved - I hope that later on I fing out how to do it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Polynomial Regression (non linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Machine Learning A-Z New/Part2-Regression/Section 6 - Polynomial Regression/Position_Salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Consultant</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager</td>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country Manager</td>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Region Manager</td>\n",
       "      <td>6</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Partner</td>\n",
       "      <td>7</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Partner</td>\n",
       "      <td>8</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C-level</td>\n",
       "      <td>9</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CEO</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level   Salary\n",
       "0   Business Analyst      1    45000\n",
       "1  Junior Consultant      2    50000\n",
       "2  Senior Consultant      3    60000\n",
       "3            Manager      4    80000\n",
       "4    Country Manager      5   110000\n",
       "5     Region Manager      6   150000\n",
       "6            Partner      7   200000\n",
       "7     Senior Partner      8   300000\n",
       "8            C-level      9   500000\n",
       "9                CEO     10  1000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45000,   50000,   60000,   80000,  110000,  150000,  200000,\n",
       "        300000,  500000, 1000000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting Linear Regression to the dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting Polynomial Regression to the dataset\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=4)\n",
    "X_poly=poly_reg.fit_transform(X)\n",
    "lin_reg2=LinearRegression()\n",
    "lin_reg2.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00],\n",
       "       [1.000e+00, 2.000e+00, 4.000e+00, 8.000e+00, 1.600e+01],\n",
       "       [1.000e+00, 3.000e+00, 9.000e+00, 2.700e+01, 8.100e+01],\n",
       "       [1.000e+00, 4.000e+00, 1.600e+01, 6.400e+01, 2.560e+02],\n",
       "       [1.000e+00, 5.000e+00, 2.500e+01, 1.250e+02, 6.250e+02],\n",
       "       [1.000e+00, 6.000e+00, 3.600e+01, 2.160e+02, 1.296e+03],\n",
       "       [1.000e+00, 7.000e+00, 4.900e+01, 3.430e+02, 2.401e+03],\n",
       "       [1.000e+00, 8.000e+00, 6.400e+01, 5.120e+02, 4.096e+03],\n",
       "       [1.000e+00, 9.000e+00, 8.100e+01, 7.290e+02, 6.561e+03],\n",
       "       [1.000e+00, 1.000e+01, 1.000e+02, 1.000e+03, 1.000e+04]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Salary')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualising Linear Regression\n",
    "plt.scatter(X,y, color='red')\n",
    "plt.plot(X, lin_reg.predict(X), color='blue')\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Salary')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising Polynomial Regression\n",
    "plt.scatter(X, y, color='red')\n",
    "plt.plot(X,lin_reg2.predict(poly_reg.fit_transform(X)), color='blue' )\n",
    "plt.title('Polynomial Regression')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decision tree (non linear and non continous regression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Section 8 - Decision Tree Regression/Position_Salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Consultant</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager</td>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country Manager</td>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Region Manager</td>\n",
       "      <td>6</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Partner</td>\n",
       "      <td>7</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Partner</td>\n",
       "      <td>8</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C-level</td>\n",
       "      <td>9</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CEO</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level   Salary\n",
       "0   Business Analyst      1    45000\n",
       "1  Junior Consultant      2    50000\n",
       "2  Senior Consultant      3    60000\n",
       "3            Manager      4    80000\n",
       "4    Country Manager      5   110000\n",
       "5     Region Manager      6   150000\n",
       "6            Partner      7   200000\n",
       "7     Senior Partner      8   300000\n",
       "8            C-level      9   500000\n",
       "9                CEO     10  1000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,1:2].values\n",
    "y=data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting Decision Tree Regression to the dataset\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor=DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting a result\n",
    "y_pred=regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45000.,   50000.,   60000.,   80000.,  110000.,  150000.,\n",
       "        200000.,  300000.,  500000., 1000000.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150000.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1=regressor.predict(6.3)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Decision Tree Regression')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising Decision Tree Regression\n",
    "plt.scatter(X,y, color='red')\n",
    "plt.plot(X, y_pred, color='blue')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Decision Tree Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Decision Tree Regression')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Because Decission Tree Regression is non continous model, the above plot is is inappropriate to show the results\n",
    "# The better plot is shown below\n",
    "# it splits the whole range of the independent variables into different intervals \n",
    "X_grid = np.arange(min(X), max(X), 0.01)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X,y, color='red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color='blue')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Decision Tree Regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Exercise-predicting prices of apartments using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions=pd.read_excel('/home/kinga/python/Machine_Learning/transakcje_mieszkania.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Adres', 'Cena', 'Cena_lokalu', 'Cena_z/m2',\n",
       "       'Data_transakcji', 'Forma obrotu', 'Funkcja dominujca',\n",
       "       'Funkcja podstawowa', 'Identyfikator', 'Ilo_izb', 'Kondygnacja',\n",
       "       'Liczba i rodzaj pomieszcze przynalenych', 'Nr zmiany', 'Numer KW',\n",
       "       'Numer transakcji/wyceny', 'Obrb', 'Opis', 'Opis nieruchomoci',\n",
       "       'Podstawa prawna', 'Pole powierzchni pomieszcze przynalenych',\n",
       "       'powierzchnia_lokalu', 'Rodzaj nieruchomoci', 'Rodzaj obcienia',\n",
       "       'Rodzaj prawa objtego transakcj', 'Rodzaj zapisu', 'repertorium',\n",
       "       'Udzia w prawie bdcy przedmiotem transakcji',\n",
       "       'Uzbrojenie istniejce', 'Uzbrojenie moliwe do podczenia',\n",
       "       'Wsprzdne geometryczne rodka budynku', 'miasto', 'adres_miasto',\n",
       "       'ulica', 'numer_mieszkania', 'wspolrzedne', 'dlugosc', 'szerokosc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions=transactions[['Kondygnacja', 'Ilo_izb', 'powierzchnia_lokalu', 'dlugosc', 'szerokosc', 'Cena_z/m2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting rows with NaN values\n",
    "transactions.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "X=transactions[['Kondygnacja', 'Ilo_izb', 'powierzchnia_lokalu', 'dlugosc', 'szerokosc']]\n",
    "# dependent variable\n",
    "y=transactions.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kondygnacja</th>\n",
       "      <th>Ilo_izb</th>\n",
       "      <th>powierzchnia_lokalu</th>\n",
       "      <th>dlugosc</th>\n",
       "      <th>szerokosc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>52.392632</td>\n",
       "      <td>16.975701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.393696</td>\n",
       "      <td>16.982495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.9</td>\n",
       "      <td>52.389267</td>\n",
       "      <td>16.985485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>52.392632</td>\n",
       "      <td>16.975701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.8</td>\n",
       "      <td>52.392632</td>\n",
       "      <td>16.975701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kondygnacja  Ilo_izb  powierzchnia_lokalu    dlugosc  szerokosc\n",
       "482          8.0        3.0                 45.5  52.392632  16.975701\n",
       "541          1.0        5.0                 64.0  52.393696  16.982495\n",
       "721          7.0        4.0                 62.9  52.389267  16.985485\n",
       "742          6.0        4.0                 79.0  52.392632  16.975701\n",
       "926         15.0        3.0                 48.8  52.392632  16.975701"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482    5714.29\n",
       "541    4796.88\n",
       "721    4960.25\n",
       "742    3797.47\n",
       "926    4846.31\n",
       "Name: Cena_z/m2, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "def get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n",
    "    model.fit(X_train, y_train) \n",
    "    y_pred=model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 10  \t\t Mean Absolute Error:  791\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  774\n",
      "Max leaf nodes: 70  \t\t Mean Absolute Error:  792\n",
      "Max leaf nodes: 100  \t\t Mean Absolute Error:  798\n",
      "Max leaf nodes: 200  \t\t Mean Absolute Error:  839\n",
      "Max leaf nodes: 300  \t\t Mean Absolute Error:  859\n",
      "Max leaf nodes: 400  \t\t Mean Absolute Error:  891\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  898\n",
      "Max leaf nodes: 600  \t\t Mean Absolute Error:  913\n",
      "Max leaf nodes: 700  \t\t Mean Absolute Error:  923\n",
      "Max leaf nodes: 800  \t\t Mean Absolute Error:  928\n"
     ]
    }
   ],
   "source": [
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [10, 50,70, 100, 200, 300, 400, 500, 600, 700, 800]:\n",
    "    my_mae = get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774.3892417887225\n"
     ]
    }
   ],
   "source": [
    "regressor=DecisionTreeRegressor(max_leaf_nodes=50, random_state=1)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# predicting prices\n",
    "y_pred=regressor.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Random Forest (non linear and non continous regression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kinga/python/Machine_Learning/Machine Learning A-Z New/Part2-Regression\n"
     ]
    }
   ],
   "source": [
    "cd '/home/kinga/python/Machine_Learning/Machine Learning A-Z New/Part2-Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data\n",
    "data=pd.read_csv('Section 8 - Decision Tree Regression/Position_Salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Consultant</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager</td>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country Manager</td>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Region Manager</td>\n",
       "      <td>6</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Partner</td>\n",
       "      <td>7</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Partner</td>\n",
       "      <td>8</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C-level</td>\n",
       "      <td>9</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CEO</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level   Salary\n",
       "0   Business Analyst      1    45000\n",
       "1  Junior Consultant      2    50000\n",
       "2  Senior Consultant      3    60000\n",
       "3            Manager      4    80000\n",
       "4    Country Manager      5   110000\n",
       "5     Region Manager      6   150000\n",
       "6            Partner      7   200000\n",
       "7     Senior Partner      8   300000\n",
       "8            C-level      9   500000\n",
       "9                CEO     10  1000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variable\n",
    "X=data.iloc[:, 1:2].values\n",
    "# dependent variable\n",
    "y=data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45000,   50000,   60000,   80000,  110000,  150000,  200000,\n",
       "        300000,  500000, 1000000])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 48850.        ,  50916.66666667,  59550.        ,  76866.66666667,\n",
       "       106933.33333333, 141966.66666667, 190700.        , 292500.        ,\n",
       "       480333.33333333, 806666.66666667])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting Random Forest Regression to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor=RandomForestRegressor(n_estimators=300, random_state=0)\n",
    "regressor.fit(X, y)\n",
    "regressor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160333.33333333])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the result\n",
    "regressor.predict(6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Decision Tree Regression')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising the results\n",
    "X_grid = np.arange(min(X), max(X), 0.01)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X,y, color='red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color='blue')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('Decision Tree Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
